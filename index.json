[{"authors":null,"categories":null,"content":"I am an Assistant Professor in Statistics at Universiti Brunei Darussalam, the leading higher education institution in Brunei. My research interests lie in statistical theory, methods and computation, with a special inclination towards social science applications.\nI obtained my PhD in Statistics from the London School of Economics and Political Science (LSE) in October 2018. My PhD project explored the use of Fisher information-dependent priors in a vector space framework for regression, classification, and variable selection. My supervisors were Dr. Wicher Bergsma and Prof. Irini Moustaki. I also obtained an MSc in Statistics from LSE in 2014.\nI graduated from Warwick University, completing the 4-year MMORSE degree in 2010. As my final year project, I used Bradley-Terry models applied to English Premier League football data. This project was supervised by Prof. David Firth.\nPreviously, I was a Research Officer at the Centre of Science \u0026amp; Technology, Research \u0026amp; Development (CSTRAD), Ministry of Defence, Brunei. My primary task was to provide data analysis and decision support to strategic acquisition projects, and assist in statistical analyses for defence-related research.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1717483334,"objectID":"4be3b5c569b714876b11c3c9391957b9","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am an Assistant Professor in Statistics at Universiti Brunei Darussalam, the leading higher education institution in Brunei. My research interests lie in statistical theory, methods and computation, with a special inclination towards social science applications.","tags":null,"title":"Haziq Jamil","type":"authors"},{"authors":null,"categories":null,"content":"Guides on writing research proposals  Sample template Writing and effective proposal  Sample FYP Research Proposals  The Effect of Dormitory Living on Academic Performance of UBD Students Statistical Analysis on Life Expectancy and GFP Building a Pitch Control Model and Understanding the Mathematics behind it Spatial Concentration Analysis: Factors Affecting Brunei’s House Prices Survival Analysis on Brunei Darussalam’s Undergrowing Population The Statistical Analysis on Knife Crimes in Boroughs of London  Sample FYP Reports  The Effect of Dormitory Living on Academic Performance of UBD Students Bayesian Variable Selection Linear Models The Statistical Investigation on The Possible Factors of Crime In London boroughs Statistical Analysis on the correlation of Socioeconomy on Life Expectancy Predicting criminal recidivism: Comparing Statistical and Machine Learning Predictive Discovering Trends in an Online Microfinance Platform: A Statistical Analysis on Kiva.org Investigation on UBD Students’ Confidence in Hypothesis Test Concepts  Presentation Advice  Condensing two semesters worth of work into 10 minutes can be challenging. Choose only the most important and noteworthy results to share. Ensure that you presentation is cohesive: there should be a beginning, a middle and an end which all flows together nicely. If you’re struggling what to talk about, just picture telling the audience a story: what is the research problem, what have you done, and what have you found out? Practice, practice, practice! Public speaking may not come naturally to everyone, so it really helps if you practice beforehand. This way you can time your presentation accordingly and make adjustments if necessary, too. Supplement your slides with appropriate graphics/tables and plan what you want to say during the presentation. It’s a bad habit to just read off the presentation slides. Do not panic. You are in a safe environment. No one will make fun of you if you slip up! Speak clearly and at a normal pace. Anticipate what questions might be asked of your presentation so you can be prepared. Have fun, and don’t forget to smile!  ","date":166536e4,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1717483334,"objectID":"b5f10d24fd964c2def52f9bbc2c3f827","permalink":"https://haziqj.ml/teaching/fyp/","publishdate":"2022-10-10T00:00:00Z","relpermalink":"/teaching/fyp/","section":"teaching","summary":"Guides on writing research proposals  Sample template Writing and effective proposal  Sample FYP Research Proposals  The Effect of Dormitory Living on Academic Performance of UBD Students Statistical Analysis on Life Expectancy and GFP Building a Pitch Control Model and Understanding the Mathematics behind it Spatial Concentration Analysis: Factors Affecting Brunei’s House Prices Survival Analysis on Brunei Darussalam’s Undergrowing Population The Statistical Analysis on Knife Crimes in Boroughs of London  Sample FYP Reports  The Effect of Dormitory Living on Academic Performance of UBD Students Bayesian Variable Selection Linear Models The Statistical Investigation on The Possible Factors of Crime In London boroughs Statistical Analysis on the correlation of Socioeconomy on Life Expectancy Predicting criminal recidivism: Comparing Statistical and Machine Learning Predictive Discovering Trends in an Online Microfinance Platform: A Statistical Analysis on Kiva.","tags":null,"title":"SM-4290 Research Project (a.k.a. Final Year Project)","type":"book"},{"authors":null,"categories":null,"content":"I will be teaching SM4202 for the first half of the semester (roughly 7 weeks) for the August 2020 semester.\nSyllabus Here are the topics I intend to cover for this course. This may change depending on how we get on with the course.\n  Chapter 1: Probability recap\n Recall fundamental concepts in mathematical probability Recap of discrete and continuous distributions Properties of means and variances Generating functions     Chapter 2: Discrete time stochastic processes\n Definitions and examples Discrete Markov chains Transition probabilities, stationary transition probabilities, $n$-step transition matrices Chapman-Kolmogorov equations State diagrams and classification of states Periodicity, recurrence and transience     Chapter 3: Continuous time stochastic processes\n Basic concepts and definitions Instantaneous transition rates $Q$ matrices (generator matrices) Kolmogorov equations Invariant measures for irreducible, continuous Markov processes     Schedule  W4 Tue 18/8/2020 1330-1530 @ 1A.62; Lecture (Chapter 1) W4 Wed 19/8/2020 1330-1530 @ 1A.62; Lecture (Chapter 1) W5 Tue 25/8/2020 1300-1530 @ 1A.62; Lecture (Chapter 2) W5 Wed 26/8/2020 1230-1400 @ 1A.62; Lecture (Chapter 2) W5 Sat 29/8/2020 0800-1000 @ 1A.62; Tutorial (Exercise 1) W6 Tue 01/9/2020 1330-1530 @ 1A.62; Lecture (Chapter 2) W6 Wed 02/9/2020 1330-1530 @ 1A.62; Lecture (Chapter 2) W6 Sat 05/9/2020 0800-1000 @ 1A.62; Tutorial (Exercise 2) W7 Tue 08/9/2020 1330-1530 @ 1A.62; Lecture (Chapter 3) W7 Wed 09/9/2020 1330-1530 @ 1A.62; Lecture (Chapter 3) MIDSEM Mon 14/9/2020 0800-1100 @ 1A.62; Lecture and Tutorial (Chapter 3 \u0026amp; Exercise 3)   CLASS TEST is scheduled for Sat 26/9/2020 @ 0830-0930. Covers Chapters 1 and 2 only.   Lecture Notes Download lecture notes from my shared Google Drive.\nExercise Sheets  Exercise 1 / Solutions Exercise 2 / Solutions Exercise 3 / Solutions  Statistical Tables  Link  Supplementary Reading  Ross, S. (2009). A First Course in Probability. Ross, S. M. (2014). Introduction to probability models. Academic Press. Grimmet, G. \u0026amp; Stirzaker, D. (2020). Probability and Random Processes. Oxford University Press. Norris, J. R. (1998). Markov Chains. Cambridge University Press.  Other Links  Epsilon-Delta Definition of Continuity Simulating an Epidemic (3B1B)  ","date":1596585600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1717483334,"objectID":"fd0c9beea1be234b0d071bd85b3871ec","permalink":"https://haziqj.ml/teaching/sm4202utb/","publishdate":"2020-08-05T00:00:00Z","relpermalink":"/teaching/sm4202utb/","section":"teaching","summary":"UTB School of Applied Sciences and Mathematics module (10 credits). This module covers stochastic processes through a wide range of applications that will develop probabilistic intuition.","tags":null,"title":"SM4202 Random Processes","type":"book"},{"authors":null,"categories":null,"content":"Semester I 2022/23 (Aug 2022) syllabus: PDF\nFor UBD Maths Majors, if you’re considering taking this module or have questions relating to it and how it fits in your overall module selection, feel free to reach out to me.\n","date":1580947200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1717483334,"objectID":"304721c7cf8fe98c10b3ac58bdc3abbe","permalink":"https://haziqj.ml/teaching/sm4335/","publishdate":"2020-02-06T00:00:00Z","relpermalink":"/teaching/sm4335/","section":"teaching","summary":"In this course, we attempt to give a mathemtically rigorous treatment to the theory of probability. We will study concepts in set theory and measure theory that will allows us to properly define the concepts of probability, distributions, and expectations.","tags":null,"title":"SM-4335 Advanced Probability","type":"book"},{"authors":null,"categories":null,"content":"General Please download RStudio onto your laptops. Install the tidyverse package by running install.packages(\u0026#34;tidyverse\u0026#34;) in the R terminal. You may like to follow along during class as I present the R codes, so bring along your laptops to class if you wish.\nSchedule  Mon 19/10/2020 1000-1200 ONLINE; Exploratory Data Analysis Mon 26/10/2020 1000-1200 ONLINE; Hypothesis Testing Mon 9/11/2020 1000-1200 ONLINE; Linear Regression  Lecture Slides  Lecture 1 Lecture 2 Lecture 3  Resources  Titanic data set Poverty data set  ","date":1580947200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1717483334,"objectID":"17d915586a439e835f95db81be0d59f3","permalink":"https://haziqj.ml/teaching/sr5101/","publishdate":"2020-02-06T00:00:00Z","relpermalink":"/teaching/sr5101/","section":"teaching","summary":"UBD Masters Module—This module is designed to provide new graduate students involved in research in the sciences with the skills and resources needed for successful research.","tags":null,"title":"SR-5101 Advanced Research Skills","type":"book"},{"authors":null,"categories":null,"content":" HTML PDF  ","date":1559865600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1717483334,"objectID":"141a8a297a9a85ec87a90adf81618260","permalink":"https://haziqj.ml/teaching/linearregression/","publishdate":"2019-06-07T00:00:00Z","relpermalink":"/teaching/linearregression/","section":"teaching","summary":"Learn the basics of linear models.","tags":null,"title":"Crash Course in Linear Regression","type":"book"},{"authors":null,"categories":null,"content":"  -- Table of Contents  Lectures  Lecture 1: Introduction to the Data Science Framework Lecture 2: Introduction to R Lecture 3: Data Science with R Pt. 1 Lecture 4: Data Science with R Pt. 2   Assignment    -- The aims of this short course are the following:\n To become familiar with the data science framework. To become familiar with the R programming language and the Integrated Development Environment (IDE) RStudio. To be able to import, summarise and visualise data in RStudio. To complete and report on an exploratory data analysis of the Kiva.org global loans dataset.  The course is delivered in the form of lecture-style presentation, with hands-on and interactive R sessions, so please bring your laptops with you (and have RStudio pre-installed). Four 2-hour lectures are planned (see below for details of each lecture). There is one assignment for this course, and there are mini exercises at the end of lectures.\nThis page will be updated as and when the material becomes ready.\n Please download R and RStudio Desktop before attending the lectures.   Lectures Lecture 1: Introduction to the Data Science Framework Slides Resources:\n Machine Learning and Data Science talk by Neil Lawrence R for Data Science Data Science Wiki page NEW Inference vs Prediction @ Data Science Blog NEW Inference vs Prediction @ Stack Exchange NEW Bias-Variance tradeoff @ Towards Data Science NEW Bias-Variance tradeoff @ Scott Fortmann  Lecture 2: Introduction to R Notes R Exercise Resources:\n Hands on Programming with R R Packages  Lecture 3: Data Science with R Pt. 1 Walk through of Chapters 2–3 of R for Data Science book.\nLecture 4: Data Science with R Pt. 2 Notes Walk through of Chapters 4–8 of R for Data Science book.\nAssignment CSTRAD July 2019 class leaders:\n Team A: Vincent Team B: Wen Jei  Due on 2nd August 2019 12.00pm.\n Data Science Framework This section to be updated.\n  Getting Started with R Key ideas Objects R works on objects. All objects have the following properties (referred to as intrinsic attributes): mode: tells us what kind of thing the object is – possible modes include numeric, complex, logical, character and list.\n  R data science functions As usual, before starting, load all the packages you need. library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.4 ✓ dplyr 1.\n  Assignment Assignment You are tasked with conducting an exploratory data analysis of the Kiva.org loans data set. In particular, focus on the following tasks: Investigate the relationship between the loan taker’s ability to pay and the usage of the loan (what it was funded for).\n  ## Meet your instructor Haziq Jamil ## FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   -- ","date":1559865600,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1717483334,"objectID":"e97db74d5e4b05828d886b8e74c6b4e0","permalink":"https://haziqj.ml/teaching/datascience/","publishdate":"2019-06-07T00:00:00Z","relpermalink":"/teaching/datascience/","section":"teaching","summary":"Learn about the data science framework, including importing, summarising, and visualising data using R.","tags":null,"title":"Introductory Data Science using R","type":"book"},{"authors":null,"categories":null,"content":"This section to be updated.\n","date":1562281200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"f41a1db61e9db11454d74c0cde17b86f","permalink":"https://haziqj.ml/teaching/datascience/1-intro/","publishdate":"2019-07-05T00:00:00+01:00","relpermalink":"/teaching/datascience/1-intro/","section":"teaching","summary":"This section to be updated.","tags":null,"title":"Data Science Framework","type":"book"},{"authors":null,"categories":null,"content":"Key ideas Objects R works on objects. All objects have the following properties (referred to as intrinsic attributes):\n mode: tells us what kind of thing the object is – possible modes include numeric, complex, logical, character and list. length: is the number of components that make up the object.  At the simplest level, an object is a convenient way to store information. In statistics, we need to store observations of a variable of interest. This is done using a numeric vector. Note that there are no scalars in R; a number is just a numeric vector of length 1. Vectors are referred to as atomic structures; all of their components have the same mode.\nIf an object stores information, we need to name it so that we can refer to it later (and thus recover the information that it contains). The term used for the name of an object is identifier. An identifier is something that we choose. Identifiers can be chosen fairly freely in R. The points below are a few simple rules to bear in mind.\n In general any combination of letters, digits and the dot character can be used although it is obviously sensible to choose names that are reasonably descriptive. You cannot start an identifier with a digit or a dot so moonbase3.sample is acceptable but 3moons.samplebase and .sample3basemoon are not. Identifiers are CASE SENSITIVE so moon.sample is different from moon.Sample. It is easy to get caught out by this. Some characters are already assigned values. These include c, q, t, C, D, F, I and T. Avoid using these as identifiers.  Typically we are interested in data sets that consist of several variables. In R, data sets are represented by an object known as a data frame. As with all objects, a data frame has the intrinsic attributes mode and length; data frames are of mode list and the length of a data frame is the number of variables that is contains. In common with many larger objects, a data frame has other attributes in addition to mode and length. The non-intrinsic attributes of a data frame are:\n names: these are the names of the variables that make up the data set; row.names: these are the names of the individuals on whom the observations are made; class: this attribute can be thought of as a detailed specification of the kind of thing the object is; in this case the class is data.frame.  The class attribute tells certain functions (generic functions) how to deal with the object. For example, objects of class “data.frame” are displayed on screen in a particular way.\nFunctions, arguments and return values R works by calling functions. The notion of a function is a familiar one; a function takes a collection of inputs and maps them to a single output. In R, inputs and output are objects. The inputs are referred to as arguments and the output is referred to as the return value. Many useful functions are part of the standard R setup. Others are available via the inclusion of packages. One of the key advantages of R is the ease with which users can define their own functions. Functions are also objects; the mode of a function is function (sensibly enough). In computing, functions have side-effects. For example, calling a function may cause a graph to be drawn. In many instances, it is the side-effect that is important rather than the return value.\nWorkspace and working directories During an R session, a number of objects will be generated; for example we may generate vectors, data frames and functions. For the duration of the session, these objects are stored in an area of memory referred to as the workspace. If we want to save the objects for future use, we instruct R to write them to a file in our current working directory (directory is just another name for a folder). Note the distinction: things in memory are temporary (they will be lost when we log out); files are more permanent (they are stored on disk and the information they contain can be loaded into memory during our next session). Managing objects and files is an important part of using R effectively.\nA new R session Starting up If you haven’t already, download R and RStudio based on your operating system. R can actually be run in the terminal (type r in your terminal) or the original R program itself.\nWe will be working in RStudio, which is a user-friendly integrated development environment (IDE).\nIt is recommended to create a project, which automatically configures the working directory. To do this, go to $\\text{File} \\rightarrow \\text{New project…}$. If your files are already in a folder, select $\\text{Existing Directory}$; otherwise select $\\text{New Directory}$. Don’t select $\\text{Version Control}$ for now.\nUsing R as a calculator The simplest thing that R can do is evaluate arithmetic expressions.\n1 + 1 ## [1] 2 1 + 4.23 ## [1] 5.23 1 + 1/2 * 9 - 3.14 ## [1] 2.36 # Note the order in which operations are performed in the final calculation  Comments in R. R ignores anything after a # sign in a command. We will follow this convention. Anything after a # in a …","date":1562601600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"2b57d90671a2868387173fa0904650e0","permalink":"https://haziqj.ml/teaching/datascience/2-intro-to-r/","publishdate":"2019-07-09T00:00:00+08:00","relpermalink":"/teaching/datascience/2-intro-to-r/","section":"teaching","summary":"Key ideas Objects R works on objects. All objects have the following properties (referred to as intrinsic attributes):\n mode: tells us what kind of thing the object is – possible modes include numeric, complex, logical, character and list.","tags":null,"title":"Getting Started with R","type":"book"},{"authors":null,"categories":null,"content":"As usual, before starting, load all the packages you need.\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.4 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 2.0.1 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() Data management Importing data sets Data can be imported by going to $\\text{File}\\rightarrow\\text{Import Dataset}$. Alternatively, the code is\n# code for importing data Converting to tibbles as_tibble(iris) ## # A tibble: 150 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows Subsetting To extract columns, use the $ symbol.\niris$Sepal.Length ## [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 ## [19] 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 ## [37] 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0 7.0 6.4 6.9 5.5 ## [55] 6.5 5.7 6.3 4.9 6.6 5.2 5.0 5.9 6.0 6.1 5.6 6.7 5.6 5.8 6.2 5.6 5.9 6.1 ## [73] 6.3 6.1 6.4 6.6 6.8 6.7 6.0 5.7 5.5 5.5 5.8 6.0 5.4 6.0 6.7 6.3 5.6 5.5 ## [91] 5.5 6.1 5.8 5.0 5.6 5.7 5.7 6.2 5.1 5.7 6.3 5.8 7.1 6.3 6.5 7.6 4.9 7.3 ## [109] 6.7 7.2 6.5 6.4 6.8 5.7 5.8 6.4 6.5 7.7 7.7 6.0 6.9 5.6 7.7 6.3 6.7 7.2 ## [127] 6.2 6.1 6.4 7.2 7.4 7.9 6.4 6.3 6.1 7.7 6.3 6.4 6.0 6.9 6.7 6.9 5.8 6.8 ## [145] 6.7 6.7 6.3 6.5 6.2 5.9 Reshaping reshape2::melt(table(diamonds$cut, diamonds$color), var = c(\u0026#34;cut\u0026#34;, \u0026#34;color\u0026#34;)) ## cut color value ## 1 Fair D 163 ## 2 Good D 662 ## 3 Very Good D 1513 ## 4 Premium D 1603 ## 5 Ideal D 2834 ## 6 Fair E 224 ## 7 Good E 933 ## 8 Very Good E 2400 ## 9 Premium E 2337 ## 10 Ideal E 3903 ## 11 Fair F 312 ## 12 Good F 909 ## 13 Very Good F 2164 ## 14 Premium F 2331 ## 15 Ideal F 3826 ## 16 Fair G 314 ## 17 Good G 871 ## 18 Very Good G 2299 ## 19 Premium G 2924 ## 20 Ideal G 4884 ## 21 Fair H 303 ## 22 Good H 702 ## 23 Very Good H 1824 ## 24 Premium H 2360 ## 25 Ideal H 3115 ## 26 Fair I 175 ## 27 Good I 522 ## 28 Very Good I 1204 ## 29 Premium I 1428 ## 30 Ideal I 2093 ## 31 Fair J 119 ## 32 Good J 307 ## 33 Very Good J 678 ## 34 Premium J 808 ## 35 Ideal J 896 Variation Continuous variables 5-point summaries summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## ggplot(reshape2::melt(iris), aes(x = variable, y = value)) + geom_boxplot() ## Using Species as id variables    Note: in the above code, we used the melt() function in reshape2 package to aggregate the data. Explore what melt() does by running it in the console.\nHistograms ggplot(iris, aes(x = Sepal.Length)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.    Density plots ggplot(iris, aes(x = Sepal.Length)) + geom_density(fill = \u0026#34;blue\u0026#34;)    Discrete variables Frequency tables table(mpg$class) ## ## 2seater compact midsize minivan pickup subcompact suv ## 5 47 41 11 33 35 62 prop.table(table(mpg$class)) ## ## 2seater compact midsize minivan pickup subcompact suv ## 0.02136752 0.20085470 0.17521368 0.04700855 0.14102564 0.14957265 0.26495726 Barplots ggplot(mpg, aes(x = reorder(class, class, FUN = length))) + geom_bar() + labs(x = \u0026#34;Class\u0026#34;)    Note: The reorder() function sorts the bars… the syntax is a bit tricky to understand, so take it as is for now.\nCovariation Continuous variables Scatter plots ggplot(mpg, aes(x = displ, y = hwy)) + geom_point()    Smooth lines ggplot(mpg, aes(x = displ, y = hwy)) + geom_smooth() ## `geom_smooth()` using method = \u0026#39;loess\u0026#39; and formula \u0026#39;y ~ x\u0026#39;    Binning ggplot(mpg, aes(x = displ, y = hwy)) + geom_boxplot(aes(group = cut_width(displ, 0.5)))    Discrete variables Contingency tables table(diamonds$cut, diamonds$color) ## ## D E F G H I J ## Fair 163 224 312 314 303 175 119 ## Good 662 933 909 871 702 522 307 ## Very Good 1513 2400 2164 2299 1824 1204 678 ## Premium 1603 2337 2331 2924 2360 1428 808 ## Ideal 2834 3903 3826 4884 3115 2093 896 t(table(diamonds$cut, diamonds$color)) ## ## Fair Good Very Good Premium Ideal ## D 163 662 1513 1603 2834 ## E 224 933 2400 2337 3903 ## F 312 909 2164 2331 3826 ## G 314 871 2299 2924 4884 ## H 303 702 1824 2360 3115 ## I 175 522 1204 1428 2093 ## J …","date":1563292800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"bf04761d520cce441a24f994d051ea45","permalink":"https://haziqj.ml/teaching/datascience/3-r4ds/","publishdate":"2019-07-17T00:00:00+08:00","relpermalink":"/teaching/datascience/3-r4ds/","section":"teaching","summary":"As usual, before starting, load all the packages you need.\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.4 ✓ dplyr 1.","tags":null,"title":"Useful data science functions in R","type":"book"},{"authors":null,"categories":null,"content":"Assignment You are tasked with conducting an exploratory data analysis of the Kiva.org loans data set. In particular, focus on the following tasks:\n  Investigate the relationship between the loan taker’s ability to pay and the usage of the loan (what it was funded for).\n  Preliminary analysis of predictive risk for new clients. What sort of characteristics are associated with high defaulting loans?\n  Explore interesting statistics segregated by regions, e.g. in Asia, what are loans most used for?\n  Can it be said that the Kiva.org loans make a positive impact to society? Perhaps, a region which sees a large number of approved microloans will measure better on a certain metric (e.g. unemployment rate) than in areas do not?\n  Is there any evidence of gender discrepancy in the number or amount of loans being funded?\n  Instructions For each of the questions above, think about\n What data do you need? What transformations and summaries do you need to perform on the data? What kind of plots do you want to visualise?  Prepare an R script file containing the R code that you used for all of your exploratory analysis of the data set, including importing, transforming, visualising, and any statistical summaries of the data.\nThe R script file should be clearly anotated with your comments, such that the next person who reads your R script understands the intent behind your code.\nMake use of commenting to write down any notes or conclusions that you have regarding the analyses.\nData set The main data set that you will have at your disposal are the four .csv files from Kaggle. You might find that there are data that you require for your analysis that is not present in the data set. Try to find additional sources of data from the web for your needs.\nPresenting your work Submit your R script to me for evaluation. The fourth lecture of this course will be dedicated to a group discussion of the five exploratory data analysis tasks above.\n","date":1563231600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"386beae0d58efd8e84b3ec85da334eac","permalink":"https://haziqj.ml/teaching/datascience/4-assignment/","publishdate":"2019-07-16T00:00:00+01:00","relpermalink":"/teaching/datascience/4-assignment/","section":"teaching","summary":"Assignment You are tasked with conducting an exploratory data analysis of the Kiva.org loans data set. In particular, focus on the following tasks:\n  Investigate the relationship between the loan taker’s ability to pay and the usage of the loan (what it was funded for).","tags":null,"title":"Kiva.org assignment","type":"book"},{"authors":["Sakander Hayat","Azri Arfan","Asad Khan","Haziq Jamil","Mohammed J. F. Alenazi"],"categories":[],"content":"","date":17172e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"855c2d465633cc0a2081d342724628e4","permalink":"https://haziqj.ml/publication/hayat-2024-optimization/","publishdate":"2024-06-01T00:00:00+08:00","relpermalink":"/publication/hayat-2024-optimization/","section":"publication","summary":"","tags":["Correlation"],"title":"An Optimization Problem for Computing Predictive Potential of General Sum/Product-Connectivity Topological Indices of Physicochemical Properties of Benzenoid Hydrocarbons","type":"publication"},{"authors":["Haziq Jamil"],"categories":[],"content":"","date":1714435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"a39215366c6c5d7b9f65e516dff6c48e","permalink":"https://haziqj.ml/publication/jamil-spatiotemporal-2024/","publishdate":"2024-04-30T00:00:00Z","relpermalink":"/publication/jamil-spatiotemporal-2024/","section":"publication","summary":"This study presents a novel spatio-temporal analysis of property prices in Brunei Darussalam, leveraging an extensive dataset of 3,763 residential property transactions from 2015 to 2023. This research utilises Conditionally Autoregressive (CAR) models to account for the intricate spatial and temporal dependencies observed within the housing market, a method not conventionally applied in the existing literature. Another novel contribution is in showcasing the use of the Moran’s test for testing global spatial and temporal autocorrelations simultaneously, offering a simplified approach compared to the multiple panel-based approach. The study uncovered significant spatial autocorrelation and temporal trends in property prices, allowing the coefficients to be estimated reliably while controlling for spatio-temporal heterogeneity in the data. The findings demonstrate the critical influence of spatial and temporal factors on property valuations, with an Autoregressive (AR) model of order 2 emerging as the most fitting, capturing both spatial heterogeneity and temporal persistence. This insight reveals that the housing market’s reaction to changes or shocks can linger for up to six months, underscoring the importance of considering these dimensions in real estate analysis and policy formulation.","tags":["Spatio-temporal models","House price"],"title":"A spatio-temporal analysis of house prices in Brunei Darussalam","type":"publication"},{"authors":["Haziq Jamil","Fatin Usop","Huda M. Ramli"],"categories":[],"content":"","date":1714435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"894dc72b06764ae8e43743b8e9395fa5","permalink":"https://haziqj.ml/publication/jamil-leveraging-2024/","publishdate":"2024-04-30T00:00:00Z","relpermalink":"/publication/jamil-leveraging-2024/","section":"publication","summary":"This paper introduces Sparse Gaussian Processes (SGP) as an efficient solution to the computational limitations of traditional Gaussian Process Regression (GPR) in large datasets, crucial for modeling property prices. By incorporating a smaller set of inducing variables, SGPs reduce computational complexity from  to  and minimize storage needs, making them practical for extensive real-world applications. We apply SGPs to model property prices in Brunei, focusing on scenario analysis to evaluate different urban planning strategies’ impacts on property values. This approach aids in informed decision-making for sustainable urban development, aligning with the United Nations Sustainable Development Goal 11 (SDG 11) to foster inclusive, safe, resilient, and sustainable cities. Our findings underscore the potential of SGPs in spatial data analysis, providing a foundation for policymakers to integrate economic and environmental considerations into urban planning.","tags":["Spatio-temporal models","House price"],"title":"Leveraging sparse Gaussian processes for property price modelling and sustainable urban planning","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1713189600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"7ec845ddaf04ab60269ef6399656b42f","permalink":"https://haziqj.ml/talk/weighted-pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/talk/weighted-pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/","section":"event","summary":"Limited information goodness-of-fit (LIGOF) tests are increasingly recognized for their application in high-dimensional multivariate categorical data analysis. LIGOF tests address sparsity in contingency tables by leveraging summary statistics derived from univariate and bivariate residuals, effectively circumventing the reliability concerns associated with traditional goodness-of-fit tests. Previous studies on binary factor models have predominantly utilised maximum likelihood estimation, which itself can be computationally intensive when fitting large and complex models. This work examines the efficacy of LIGOF tests when composite likelihood estimation, specifically pairwise likelihood estimation, is used instead. Pairwise likelihood estimation offers a beneficial trade-off between computational efficiency and modelling accuracy in factor models, and hence the performance of LIGOF tests under this framework is of significant interest. The tests under consideration are based on quadratic forms of the residuals, including the classical Wald and Pearson tests. Modifications of these tests are also proposed, with the aim of further reducing computational complexity. Moreover, the study is expanded to include scenarios that involve complex sampling procedures with known weights, thereby broadening the applicability of our findings.","tags":["Latent variable models","Pairwise likelihood"],"title":"Weighted pairwise likelihood goodness-of-fit tests for binary factor models","type":"event"},{"authors":["Haziq Jamil","Irini Moustaki","Chris Skinner"],"categories":[],"content":"","date":1699056e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"88b867f0beeff2a7ae3aec4887ef60c0","permalink":"https://haziqj.ml/publication/jamil-pairwise-2023/","publishdate":"2023-11-04T00:00:00Z","relpermalink":"/publication/jamil-pairwise-2023/","section":"publication","summary":"This paper discusses estimation and limited information goodness-of-fit test statistics in factor models for binary data using pairwise likelihood estimation and sampling weights. The paper extends the applicability of pairwise likelihood estimation for factor models with binary data to accommodate complex sampling designs. Additionally, it introduces two key limited information test statistics: the Pearson chi-squared test and the Wald test. To enhance computational efficiency, the paper introduces modifications to both test statistics. The performance of the estimation and the proposed test statistics under simple random sampling and unequal probability sampling is evaluated using simulated data.","tags":["Composite likelihood","Latent variable models"],"title":"Pairwise likelihood estimation and limited information goodness-of-fit test statistics for binary factor analysis models under complex survey sampling","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1698325200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"63c3bcd4b19ae8547cdbbe6ae6579661","permalink":"https://haziqj.ml/talk/spatio-temporal-modelling-of-property-prices-in-brunei-darussalam/","publishdate":"2023-08-09T14:00:00Z","relpermalink":"/talk/spatio-temporal-modelling-of-property-prices-in-brunei-darussalam/","section":"event","summary":"","tags":["Spatio-temporal modelling","Property prices"],"title":"Spatio-temporal modelling of property prices in Brunei Darussalam","type":"event"},{"authors":["Oluwakemisola Onifade","Norazanita Shamsuddin","Haziq Jamil","Daphne Teck Ching Lai","Stefan Gӧdeke"],"categories":[],"content":"","date":1695686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"c513854ad5a52c4bc40da14d8c5731be","permalink":"https://haziqj.ml/publication/onifade-2023-monitoring/","publishdate":"2023-02-20T00:00:00+08:00","relpermalink":"/publication/onifade-2023-monitoring/","section":"publication","summary":"Having accurate and reliable baseline data is crucial to assess the environmental changes for an ecosystem. In this study, we illustrated the changes, pollution status, and significant causes of pollution for Brunei Darussalam’s iconic Sungai Brunei (Brunei River). Eleven parameters (pH, temperature, ORP, DO, BOD, conductivity, TDS, salinity, turbidity, ammonia-nitrogen, and total coliform) were analyzed from eight monitoring sites in 1984, 2019, 2020, and 2021. Box-plots was used for comparative study between 1984 and 2019+ data while Krustal-Wallis, HCA, and PCA tests were performed on data from recent years (2019+) respectively. The box-plot analysis showed that pollution levels in 2019, 2020, and 2021 increased compared to 1984 values, especially for total coliform bacteria. This is concerning because guideline values for fishing have now been exceeded. Krustal-Wallis tests were performed to determine if there was a statistically significant difference among monitoring locations in the 2019+ years or not. Hierarchical cluster analysis (HCA) pointed out that upstream stations Q and J are very polluted while principal component analysis (PCA) identified hydrological processes (such as runoff from the mangrove area) and anthropogenic activities as possible sources of pollution in the Brunei River. This baseline assessment is one of several steps in developing a decision support system to assist Brunei's authorities in managing river basins and estuaries and drafting policies to manage river water quality.\n","tags":["Data Analysis"],"title":"Importance of Baseline Assessments: Monitoring of Sungai Brunei River's Water Quality","type":"publication"},{"authors":["Sakander Hayat","Muhammad Adil Khan","Asad Khan","Haziq Jamil","Muhammad Yasir Hayat Malik"],"categories":[],"content":"","date":169344e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"1ae99fd6887370c748e985480241c37d","permalink":"https://haziqj.ml/publication/hayat-2023-extremal/","publishdate":"2023-06-27T00:00:00+08:00","relpermalink":"/publication/hayat-2023-extremal/","section":"publication","summary":"","tags":["Correlation"],"title":"Extremal hyper-Zagreb index of trees of given segments with applications to regression modeling in QSPR studies","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1691589600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"4fe8f868878e9c828a1d6f52f241155b","permalink":"https://haziqj.ml/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/","publishdate":"2023-08-09T14:00:00Z","relpermalink":"/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/","section":"event","summary":"","tags":["Latent variable models","Pairwise likelihood"],"title":"Pairwise likelihood goodness of fit tests for binary factor models","type":"event"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1690474200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"9e79bf8d10a2236f13969d6e006a204a","permalink":"https://haziqj.ml/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/","section":"event","summary":"Limited information goodness of fit (GOF) tests have gained recognition in the literature for high-dimensional multivariate categorical data analysis. Sparsity issues in the ensuing contingency tables impair the dependability of GOF tests but can be circumvented by considering summary statistics involving univariate and bivariate residuals. Prior work in this area for factor models have focused mainly on maximum likelihood estimation, which itself can be computationally intensive when fitting large and complex models. This present work examines limited information GOF tests when composite likelihood estimation, specifically pairwise likelihood estimation, is used instead. Pairwise likelihood estimation offers a beneficial trade-off between computational efficiency and modelling accuracy in factor models, and hence we wanted to examine the performance of limited information GOF tests under this framework. The tests under consideration are based on the Pearson chi-squared test statistic and the Wald test statistic. We propose modifications to each of these tests with the aim of further reducing computational complexity. We then extend our findings beyond independent sampling to situations where complex sampling procedures (with known weights) are employed.","tags":["Latent variable models","Pairwise likelihood"],"title":"Pairwise likelihood goodness of fit tests for binary factor models","type":"event"},{"authors":["Sakander Hayat","Nurin Suhaili","Haziq Jamil"],"categories":[],"content":"","date":1690416e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"b373c06aaf601d53e0be80ea830e0cc8","permalink":"https://haziqj.ml/publication/hayat-2023-statistical/","publishdate":"2023-06-27T00:00:00+08:00","relpermalink":"/publication/hayat-2023-statistical/","section":"publication","summary":"","tags":["Correlation"],"title":"Statistical significance of valency-based topological descriptors for correlating thermodynamic properties of benzenoid hydrocarbons with applications","type":"publication"},{"authors":["Muhammad Arshad","Sakander Hayat","Haziq Jamil"],"categories":[],"content":"","date":1687824e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"a0701715edea01132e60cf8107b4567e","permalink":"https://haziqj.ml/publication/arshad-2023-domination/","publishdate":"2023-06-27T00:00:00+08:00","relpermalink":"/publication/arshad-2023-domination/","section":"publication","summary":"","tags":["Correlation"],"title":"The domination number of the king's graph","type":"publication"},{"authors":["Wicher Bergsma","Haziq Jamil"],"categories":[],"content":"","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"a78aac33461ac75c8a0d323f2c148b1a","permalink":"https://haziqj.ml/publication/bergsma-interaction-2023/","publishdate":"2023-05-01T00:00:00+08:00","relpermalink":"/publication/bergsma-interaction-2023/","section":"publication","summary":"Additive regression models with interactions have been considered extensively in the literature, using estimation methods such as splines or Gaussian process regression. At least two difficulties have hampered their application: (i) estimating the models can be difficult due to potentially many tuning (or smoothing) parameters, and (ii) model selection may be difficult due to a lack of adequate criteria. In this paper, we attempt to address these issues with a novel approach to estimating and selecting additive models with and without interaction effects. \n\nFirstly, we extend the I-prior methodology (Bergsma, 2020) to multiple covariates, each of which may be multidimensional. For this purpose, we define a class of hierarchical interaction models assuming the regression function lies in a reproducing kernel Krein space (RKKS), and derive the (possibly indefinite) reproducing kernel for the models. The I-prior is an objective prior for a statistical parameter based on its Fisher information. In the present case, the I-prior for the regression function is Gaussian with covariance kernel proportional to its (positive definite) Fisher information, with support a subset of the assumed RKKS, i.e., the I-prior is proper. The I-prior methodology has some theoretical and practical advantages over competing methods such as Gaussian process regression and Tikhonov regularization. A practical (computational) advantage is that it permits an EM algorithm with simple E and M steps to find the maximum marginal likelihood estimators of the scale parameters (also known as tuning parameters), making their estimation easier than for competing methods.\n\nA second innovation we introduce is a parsimonious specification of models with interac- tions. That is, each covariate is assigned a single (length) scale parameter, regardless of the number of interactions present in the model. Rather than assigning a new scale parameter to tensor product spaces, these inherit the scale parameters of the components through their product. This approach is mathematically justified and has two key advantages: (i) estimation of models with interactions is simplified due to the presence of fewer scale parameters, and (ii) model selection (among models with different interactions present) is simplified, in that simply the model with the highest marginal likelihood can be chosen.\n\nThe I-prior approach is suitable for both parametric and nonparametric regressions. Our simulations show comparatively good performance for model selection in basic multiple regression with interactions. The methodology is also illustrated with a real-data example. An R-package implementing our methodology is available (Jamil, 2019).\n","tags":["RKHS","RKKS","Fisher information","empirical Bayes","I-prior"],"title":"Additive interaction modelling using I-priors","type":"publication"},{"authors":null,"categories":null,"content":"Introduction This project involves the use of quantitative methods and data analysis techniques to examine the relationships between various factors that affect the price of real estate. The importance of property prices as a macroeconomic indicator for a country cannot be overstated, as it has significant implications for the overall health of the economy. Property prices are not only an essential component of household wealth but also influence the spending patterns of consumers, the lending policies of financial institutions, and the investment decisions of businesses. Thus, understanding the dynamics of property prices through statistical modeling is crucial for policymakers, investors, and other stakeholders to make informed decisions that can affect the direction of the economy.\nResearch objectives   To conduct an overarching literature review of data analytic techniques and statistical models used in spatio-temporal analyses across various disciplines.\n  To build a statistical model suitable for both explaining and predicting property prices in Brunei, and offer sociological and economic explanations for the observed phenomena.\n  To analyse trends of house ownership from an affordability standpoint based on market price data available on alternative sources (e.g. social media), and compare its reliability with oﬀicial statistics. [c.f. RPPI]\n  Knowledge areas   Statistical modelling: Generalised linear models, Generalised additive models (GAMs), Gaussian process regression, Spatial autoregressive models.\n  Model estimation: EM algorithms, MCMC methods, INLA technique, Variational inference.\n  Economics: Hedonic regression, RPPI as a macroeconomic indicator.\n  Data analytics: Visualisation of spatial data (GIS and shape file), Automated data scraping.\n  Projects   Analysis of factors affecting residential property prices in Brunei\n  Building the RPPI using alternative sources: A comparative study in Brunei\n  Exploring factors affecting rental property prices in Brunei\n  Collating socio-demographic spatio-temporal data in Brunei for modelling purposes\n  Members   Haziq Jamil [PI]. Assistant Professor in Statistics.\n  Lutfi Abdul Razak. Lecturer in Economics.\n  Indira Puteri Kinasih. PhD Mathematics candidate.\n  Dk Nur Amira Barizah @ Dk Nur Aisyah Pg Noorosmawie. BSc Mathematics candidate\n  Nur Husnina Muhammad Zuhairi. BSc Mathematics candidate\n  Atikah Farhain Yahya. BSc Mathematics candidate\n  ","date":1677715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"3e61300e6521bc7398eb097252cec57c","permalink":"https://haziqj.ml/future-project/spatial-brunei/","publishdate":"2023-03-02T00:00:00Z","relpermalink":"/future-project/spatial-brunei/","section":"future-project","summary":"Building statistical models suitable for explaining and predicting property prices in Brunei.","tags":["Spatial Models","Property Prices","Data Analytics"],"title":"Statistical modelling of spatio-temporal data: An application to property prices in Brunei","type":"future-project"},{"authors":["Najib Noorashid","Haziq Jamil"],"categories":[],"content":"","date":1677369600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"d150e46ba8ccf0f377ea99f45612c8d0","permalink":"https://haziqj.ml/publication/noorashid-2023-foreign/","publishdate":"2023-02-26T00:00:00+08:00","relpermalink":"/publication/noorashid-2023-foreign/","section":"publication","summary":"","tags":["Correlation"],"title":"Foreign language anxiety in higher education","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1668610800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"46157bdb83405fe0ebb2e8b70806ff61","permalink":"https://haziqj.ml/talk/regression-modelling-using-i-priors/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/regression-modelling-using-i-priors/","section":"event","summary":"Regression analysis is undoubtedly an important tool to understand the relationship between one or more explanatory and independent variables of interest. The problem of estimating a generic regression function in a model with normal errors is considered. For this purpose, a novel objective prior for the regression function is proposed, defined as the distribution maximizing entropy (subject to a suitable constraint) based on the Fisher information on the regression function. This prior is called the I-prior. The regression function is then estimated by its posterior mean under the I-prior, and accompanying hyperparameters are estimated via maximum marginal likelihood. Estimation of I-prior models is simple and inference straightforward, while predictive performances are comparative, and often better, to similar leading state-of-the-art models--as will be illustrated by several data examples. Further plans for research in this area are also presented, including variable selection for interaction effects and extending the I-prior methodology to non-Gaussian errors.","tags":["Variational Inference"],"title":"Regression modelling using I-priors","type":"event"},{"authors":["Wicher Bergsma","Haziq Jamil"],"categories":null,"content":"","date":1657876500,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"d7b7725ee668910762a9d1897aed5bfb","permalink":"https://haziqj.ml/talk/selecting-interaction-effects-in-additive-models-using-i-priors/","publishdate":"2022-07-01T00:00:00Z","relpermalink":"/talk/selecting-interaction-effects-in-additive-models-using-i-priors/","section":"event","summary":"Additive models with interactions have been considered extensively in the literature, using estimation methods such as splines or Gaussian process regression. We present an alternative empirical-Bayes approach to selecting interaction effects using the I-prior approach introduced by Bergsma (2020). Using a parsimonious formulation of hierarchical interaction spaces, model selection is simplified. Furthermore, we present an efficient EM algo- rithm for estimating key hyperparameters. Simulations for linear regressions indicate competitive performance with methods such as the lasso and Bayesian variable selection using spike and slab priors or g-priors. However, our methodology is more gen- eral and can also be used with interacting nonlinear regression functions.","tags":["I-prior"],"title":"Selecting interaction effects in additive models using I-priors","type":"event"},{"authors":["Fadzilah Jali","Elvynna Leong","Haziq Jamil"],"categories":[],"content":"","date":1651536e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"1ebd22fee10dd1f6d1618837bbdc7359","permalink":"https://haziqj.ml/publication/jali-2022-factors/","publishdate":"2021-09-06T14:10:51.579541Z","relpermalink":"/publication/jali-2022-factors/","section":"publication","summary":"The objective of this study is to examine the socio-demographic factors contributing to the readmission to a drug rehabilitation centre amongst drug addicts in Brunei Darussalam. This retrospective study used de-identified data obtained from the Al-Islah Rehabilitation Centre for the period 1st January 2010 to 31st December 2017. Univariate and multiple logistic regression analyses with stepwise variable selection method were used to estimate and determine significant factors associated with readmission to the centre. A total of 92 out of 705 subjects (13.0%) were readmitted to the rehabilitation centre within the study period with age ranged from 20 to 59 years (mean=36.1, sd=8.6 years). Univariate logistic regression analysis found significant association between readmission and age of onset, district, marital status, and committed other criminal offence. Multiple logistic regression found that  subjects who were in the age group of 40 to 49 (odds ratio, OR= 2.24; 95% CI: 1.16 - 4.37), resided in the Belait district (OR= 1.94; 95% CI: 1.00 - 3.63), divorced or widowed (OR= 2.14; 95% CI: 1.19 - 3.82), had committed other criminal offences (OR= 1.91; 95% CI: 1.16 - 3.11), and voluntarily admitted (OR= 2.33; 95% CI: 1.34 - 4.01) were found to be significantly more likely to get readmitted to the rehabilitation centre. This study provides evidence of socio-demographic factors in relation to readmission to the rehabilitation centre in Brunei Darussalam. However, it is recommended for future researchers to explore other statistical analyses such as survival analysis or mixed methods research, combining both qualitative and quantitative research, to compare the findings of the study.\n","tags":["Logistic Regression"],"title":"Factors Affecting Readmission to a Drug Rehabilitation Centre in Brunei Darussalam","type":"publication"},{"authors":["Stefan Gӧdeke","Haziq Jamil","Mario Schirmer","Anja Bretzler","Norazanita Shamsuddin","Nur Hakimah Mansor"],"categories":[],"content":"","date":1648512e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"e3e41a2cc0e48807b9f4f46f6e50e7ab","permalink":"https://haziqj.ml/publication/godeke-2022-increase/","publishdate":"2021-09-06T14:10:51.579541Z","relpermalink":"/publication/godeke-2022-increase/","section":"publication","summary":"The aim of this research was the analysis of the effect of a dam height raise on the water quality of a tropical reservoir used for drinking water purposes in Southeast Asia. A particular focus of this study was the analysis of iron and manganese concentrations, a common problem in drinking water reservoirs, which can be released from the sediment under anoxic conditions. Analysis of iron, manganese, pH and ammonia were performed over a 5-year period from daily water sampling at the reservoir.  In addition, high frequency monitoring data of nitrate, ammonium, pH and blue green algae were obtained using a monitoring probe. The results showed that due to the raising of the dam water level, previously toxic sediments became submerged triggering an increase in iron and manganese in particular due to the establishment of reducing conditions. Manganese concentrations with values up to 4 mg/l are now exceeding guideline values. The analysis strongly indicated that both iron and manganese have a seasonal component with higher iron and manganese concentrations during the wet season. Over a three-year period afterwards concentrations did not go back to pre-raise levels. The change in water quality was accompanied by a change in pH from previous values of around 5 to pH values of around 6.5. This study showed that the change in water quality, in particular iron, manganese and pH due to the establishment of reducing conditions can have long-term effects on the water quality of a reservoir. \n","tags":["Time Series"],"title":"Iron and Manganese Mobilisation due to Dam Height Increase for a Tropical Reservoir in South East Asia","type":"publication"},{"authors":["Myrsini Katsikatsou","Irini Moustaki","Haziq Jamil"],"categories":[],"content":"","date":1641945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"0b0af8c523f64c5ef00ea11a3fe79ba3","permalink":"https://haziqj.ml/publication/katsikatsou-pairwise-2021/","publishdate":"2021-09-06T14:10:51.180368Z","relpermalink":"/publication/katsikatsou-pairwise-2021/","section":"publication","summary":"Methods for the treatment of item non-response in attitudinal scales and in large-scale assessments under the pairwise likelihood (PL) estimation framework and under a missing at random (MAR) mechanism are proposed. Under a full information likelihood estimation framework and MAR, ignorability of the missing data mechanism does not lead to biased estimates. However, this is not the case for pseudo-likelihood approaches such as the PL. We develop and study the performance of three strategies for incorporating missing values into confirmatory factor analysis under the PL framework, the complete-pairs (CP), the available-cases (AC) and the doubly robust (DR) approaches. The CP and AC require only a model for the observed data and standard errors are easy to compute. Doubly-robust versions of the PL estimation require a predictive model for the missing responses given the observed ones and are computationally more demanding than the AC and CP. A simulation study is used to compare the proposed methods. The proposed methods are employed to analyze the UK data on numeracy and literacy collected as part of the OECD Survey of Adult Skills.","tags":["Composite likelihood","Latent variable models"],"title":"Pairwise likelihood estimation for confirmatory factor analysis models with categorical variables and data that are missing at random","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1636902e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"5f405199a770e675ccbb012f89c23374","permalink":"https://haziqj.ml/talk/mindef-scholars-sharing-session-life-after-mindef/","publishdate":"2021-11-01T00:00:00Z","relpermalink":"/talk/mindef-scholars-sharing-session-life-after-mindef/","section":"event","summary":"Sharing experiences about life after leaving the defence sector.","tags":[],"title":"MINDEF Scholars Sharing Session: Life After MINDEF","type":"event"},{"authors":["Aida Zaini","Haziq Jamil","Elvynna Leong"],"categories":[],"content":"","date":1632873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"10592931ed9eb2bb88c0076e841e5cf4","permalink":"https://haziqj.ml/publication/zaini-2021-investigating/","publishdate":"2021-09-06T14:10:51.579541Z","relpermalink":"/publication/zaini-2021-investigating/","section":"publication","summary":"Hypothesis testing is an essential tool among researchers and practitioners alike, with its use being being widely taught in many a programme at university level. However, past studies have shown that students hold misconceptions about important statistical concepts. This present study aims to reconfirm past efforts in this area, specifically in a South East Asian higher education institution. To test how well undergraduate university students' understood key concepts in hypothesis testing, an online multiple choice questionnaire was deployed. The questionnaire also asked for students' confidence ratings for each question, allowing us to distinguish the confident versus non-confident incorrect responses. A follow-up interview was then conducted to give deeper insights into reasons behind respondents' errors. The main finding is that there are significantly more confident wrong answers than non-confident ones -- highly indicative of the presence of misconceptions among respondents. Among them, students firmly believed that statistical inference procedures provide a direct calculational proof of the null hypothesis. Additionally, students have difficulty formulating correct hypotheses to be tested, and have poor grasp of the role of signficance levels in hypothesis testing. Whether or not students were taking a quantitative-focused programme, or had prior statistics training, had no bearing on their survey score. Despite this, confidence ratings were significantly higher in both groups.","tags":[],"title":"I think I understand: Investigating misconceptions regarding hypothesis test concepts among university students","type":"publication"},{"authors":["Haziq Jamil","Huda M. Ramli","Elvynna Leong"],"categories":[],"content":"","date":1628208e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"1cb2055ce73212dd6fba88285485007e","permalink":"https://haziqj.ml/publication/jamil-advocating-2022/","publishdate":"2021-09-06T14:10:50.616027Z","relpermalink":"/publication/jamil-advocating-2022/","section":"publication","summary":"Institutional mathematics education has long been traditional in its ways of being teacher-centric, a tradition which perhaps dates back to the Ancient Greece. Much like the society in those days, where there was a wary public feeling about the rigidness of the mathematical instruction in Pythagoras' school, mathematics educators find themselves in a similar position in the common era of 2020. Unlike the Ancient Greece however, the battle is for the sustained delivery of a comprehensive mathematics education in the midst of the Covid-19 pandemic. It would be fair to say that mathematics departments across all levels of the education sector have been affected drastically; more so on instructors who favour the traditional \"chalk and talk\" method of instruction. In this article, we share several lessons learned in the delivery of mathematical instruction at undergraduate university level during the Covid-19 pandemic, drawing on our experience at Universiti Brunei Darussalam. These include specific methods for implementing online learning effectively, the pros and cons of such methods, and how we can use computer based tools to make learning more conducive. We highly think that these implementations are beneficial to be adapted by mathematics departments anywhere as a means of adapting to the new realities post Covid-19.","tags":["Automated assessments","Blended learning","Dynamic exercises","Learning management systems"],"title":"Advocating Blended Learning for University Undergraduate Level Mathematical Instruction Beyond Covid-19","type":"publication"},{"authors":["Artemis Koukounari","Haziq Jamil","Elena Erosheva","Clive Shiff","Irini Moustaki"],"categories":[],"content":"Author Summary Accurate schistosomiasis diagnosis is essential to assess the impact of large scale and repeated mass drug administration to control or even eliminate this disease. However, in schistosomiasis diagnostic studies, several inherent study design issues pose a real challenge for the currently available statistical tools used for diagnostic modelling and associated data analysis and conclusions. More specifically, those study design issues are:\n the inclusion of small number of diagnostic tests (i.e. most often five), non formal consensus about a schistosomiasis gold standard, the contemporary use of relatively small sample sizes in relevant studies due to lack of research funding, the differing levels of prevalence of the studied disease even within the same area of one endemic country and other real world factors such as: the lack of appropriate equipment, the variability of certain methods due to biological phenomena and training of technicians across the endemic countries because of scarce financial resources contributing to the existing lack of a schistosomiasis gold standard. The current study aims to caution practitioners from blindly applying statistical models with small number of diagnostic tests and sample sizes, proposing design guidelines of future schistosomiasis diagnostic accuracy studies with recommendations for further research. While our study is centred around the diagnosis of schistosomiasis, we feel that the recommendations can be adapted to other major tropical infectious diseases as well.  ","date":1612396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"12351fa741562a2a5a3a5655384bab57","permalink":"https://haziqj.ml/publication/koukounari-latent-2021/","publishdate":"2021-09-06T14:10:51.313481Z","relpermalink":"/publication/koukounari-latent-2021/","section":"publication","summary":"Various global health initiatives are currently advocating the elimination of schistosomiasis within the next decade. Schistosomiasis is a highly debilitating tropical infectious disease with severe burden of morbidity and thus operational research accurately evaluating diagnostics that quantify the epidemic status for guiding effective strategies is essential. Latent class models (LCMs) have been generally considered in epidemiology and in particular in recent schistosomiasis diagnostic studies as a flexible tool for evaluating diagnostics because assessing the true infection status (via a gold standard) is not possible. However, within the biostatistics literature, classical LCM have already been criticised for real-life problems under violation of the conditional independence (CI) assumption and when applied to a small number of diagnostics (i.e. most often 3-5 diagnostic tests). Solutions of relaxing the CI assumption and accounting for zero-inflation, as well as collecting partial gold standard information, have been proposed, offering the potential for more robust model estimates. In the current article, we examined such approaches in the context of schistosomiasis via analysis of two real datasets and extensive simulation studies. Our main conclusions highlighted poor model fit in low prevalence settings and the necessity of collecting partial gold standard information in such settings in order to improve the accuracy and reduce bias of sensitivity and specificity estimates.","tags":["Latent Class Models"],"title":"Latent Class Analysis: Insights about design and analysis of schistosomiasis diagnostic studies","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":"Links  An interactive visualisation of Bayesian inference MCMC demo  References  Bollen, K. A. (1989). Structural Equations with Latent Variables. John Wiley \u0026amp; Sons. ISBN: 978-0-471-01171-2. DOI: 10.1002/9781118619179. Denwood, M. (2016). runjags: An R Package Providing Interface Utilities, Model Templates, Parallel Computing Methods and Additional Distributions for MCMC Models in JAGS. Journal of Statistical Software 71.9, pp. 1–25. DOI: 10.18637/jss.v071.i09. Edwards, J. R. and R. P. Bagozzi (2000). On the nature and direction of relationships between constructs and measures. Psychological methods 5.2, p. 155. Hafez, M. S., I. Moustaki, and J. Kuha (2015). Analysis of multivariate longitudinal data subject to nonrandom dropout. Structural Equation Modeling: A Multidisciplinary Journal 22.2, pp. 193–201. Kruschke, J. K. (2014). Doing Bayesian Data Analysis: A tutorial with R, JAGS, and Stan. Second Edition. Boston: Academic Press. ISBN: 978-0-12-405888-0. Rabe-Hesketh, S. and A. Skrondal (2008). Multilevel and longitudinal modeling using Stata. STATA press.  Sample code in JAGS model{ for (i in 1:N) { for (k in 1:p_phy) { # Physical y_phy[i,k] ~ dnorm(a_phy[k] + b_phy[k] * Phy[i], 1/v_phy[k]) } for (k in 1:p_cgn) { # Cognitive y_cgn[i,k] ~ dnorm(a_cgn[k] + b_cgn[k] * Cgn[i], 1/v_cgn[k]) } for (k in 1:p_cmb) { # Combatant y_cmb[i,k] ~ dnorm(a_cmb[k] + b_cmb[k] * Cmb[i], 1/v_cmb[k]) } Phy[i] ~ dnorm(a_Phy + b_Phy * Abl[i], 1/v_Phy) Cgn[i] ~ dnorm(a_Cgn + b_Cgn * Abl[i], 1/v_Cgn) Cmb[i] ~ dnorm(a_Cmb + b_Cmb * Abl[i], 1/v_Cmb) Abl[i] ~ dnorm(a_Abl, 1/v_Abl) } # Priors --------------------------------------------------------------------- a_phy[1] ~ dnorm(0,1e-3) b_phy[1] \u0026lt;- 1 for(k in 2:p_phy) { a_phy[k] ~ dnorm(0,1e-3) b_phy[k] ~ dnorm(0,1e-2) } for(k in 1:p_phy) { sd_phy[k] ~ dgamma(1,.5) v_phy[k] \u0026lt;- pow(sd_phy[k],2) } a_cgn[1] ~ dnorm(0,1e-3) b_cgn[1] \u0026lt;- 1 for(k in 2:p_cgn) { a_cgn[k] ~ dnorm(0,1e-3) b_cgn[k] ~ dnorm(0,1e-2) } for(k in 1:p_cgn) { sd_cgn[k] ~ dgamma(1,.5) v_cgn[k] \u0026lt;- pow(sd_cgn[k],2) } a_cmb[1] ~ dnorm(0,1e-3) b_cmb[1] \u0026lt;- 1 for(k in 2:p_cmb) { a_cmb[k] ~ dnorm(0,1e-3) b_cmb[k] ~ dnorm(0,1e-2) } for(k in 1:p_cmb) { sd_cmb[k] ~ dgamma(1,.5) v_cmb[k] \u0026lt;- pow(sd_cmb[k],2) } a_Phy \u0026lt;- 0 a_Cgn \u0026lt;- 0 a_Cmb \u0026lt;- 0 a_Abl \u0026lt;- 0 b_Phy \u0026lt;- 1 b_Cgn ~ dnorm(0,1e-2) b_Cmb ~ dnorm(0,1e-2) sd_Phy ~ dgamma(1,.5) v_Phy \u0026lt;- pow(sd_Phy,2) sd_Cgn ~ dgamma(1,.5) v_Cgn \u0026lt;- pow(sd_Cgn,2) sd_Cmb ~ dgamma(1,.5) v_Cmb \u0026lt;- pow(sd_Cmb,2) sd_Abl ~ dgamma(1,.5) v_Abl \u0026lt;- pow(sd_Abl,2) } ","date":1605796200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"f7b045ccf22c88e9f0021ae8578aad0a","permalink":"https://haziqj.ml/talk/a-latent-variable-model-for-maximal-performance-testing-with-dropouts-for-military-applications/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/a-latent-variable-model-for-maximal-performance-testing-with-dropouts-for-military-applications/","section":"event","summary":"Soldiers are expected to perform complex and demanding tasks during operations, often while carrying a heavy load. It is therefore important for commanders to understand the relationship between load carriage and soldiers’ performance, as such knowledge helps inform decision-making on training policies, operational doctrines, and future soldier systems requirements. In order to investigate this, repeated experiments were conducted to capture key soldier performance parameters under controlled conditions. The data collected was found to contain missing values due to dropouts as well as non-measurement. We propose a Bayesian structural equation model to quantify a latent variable representing soldiers’ abilities, while taking into consideration the non-random nature of the dropouts and time-varying effects. This talk describes the modelling exercise conducted, emphasising the statistical model-building process as well as the practical reporting of the outputs of the model.","tags":["Latent Variable Models","Structural Equation Models"],"title":"A latent variable model for maximal performance testing with dropouts for military applications","type":"event"},{"authors":["Haziq Jamil","Wicher Bergsma"],"categories":[],"content":"","date":1604793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"4bc150beab57160ff87735d5ba38598b","permalink":"https://haziqj.ml/publication/jamil-bayesian-2021/","publishdate":"2021-09-06T14:10:50.903444Z","relpermalink":"/publication/jamil-bayesian-2021/","section":"publication","summary":"The Bayesian approach to modelling differs from the frequentist approach primarily in the supplementation of additional information about the parameters to the data. If we specify a \"good\" prior, in the sense that the prior nudges the likelihood in the right direction, then the estimates will also be good. This is what we aim to do in the case of variable selection problems, whereby the Bayesian method reduces the selection problem to one of estimation from a true search of the variable space for the model which optimises a certain criterion. We contribute to the vastly available literature of variable selection methods by using I-priors [(Bergsma, 2019)](https://doi.org/10.1016/j.ecosta.2019.10.002)---a class of Gaussian distributions which has the distinguishing property of having covariance proportional to the Fisher information (of the model parameters). The original motivation behind the I-prior methodology was to develop a novel unifying approach to various regression models. In this work, we detail the I-prior model used, and showcase some simulation results and several real-world applications in which the I-prior performs favourably compared to other prior distributions and/or variable selection techniques in terms of model size, $R^2$, predictive ability, and so on.","tags":["Bayesian","Collinearity","Linear regression","MCMC","Variable selection"],"title":"Bayesian Variable Selection for Linear Models Using I-Priors","type":"publication"},{"authors":["Wicher Bergsma","Haziq Jamil"],"categories":[],"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"3a07da07eaf0581dae090bf0b3377086","permalink":"https://haziqj.ml/publication/bergsma-regression-2020/","publishdate":"2021-09-06T14:10:51.03903Z","relpermalink":"/publication/bergsma-regression-2020/","section":"publication","summary":"We introduce the I-prior methodology as a unifying framework for estimating a variety of regression models, including varying coefficient, multilevel, longitudinal models, and models with functional covariates and responses. It can also be used for multi-class classification, with low or high dimensional covariates. The I-prior is generally defined as a maximum entropy prior. For a regression function, the I-prior is Gaussian with covariance kernel proportional to the Fisher information on the regression function, which is estimated by its posterior distribution under the I-prior. The I-prior has the intuitively appealing property that the more information is available on a linear functional of the regression function, the larger the prior variance, and the smaller the influence of the prior mean on the posterior distribution. Advantages compared to competing methods, such as Gaussian process regression or Tikhonov regularization, are ease of estimation and model comparison. In particular, we develop an EM algorithm with a simple E and M step for estimating hyperparameters, facilitating estimation for complex models. We also propose a novel parsimonious model formulation, requiring a single scale parameter for each (possibly multidimensional) covariate and no further parameters for interaction effects. This simplifies estimation because fewer hyperparameters need to be estimated, and also simplifies model comparison of models with the same covariates but different interaction effects; in this case, the model with the highest estimated likelihood can be selected. Using a number of widely analyzed real data sets we show that predictive performance of our methodology is competitive. An R-package implementing the methodology is available (Jamil, 2019).","tags":["reproducing kernel","RKHS","RKKS","Fisher information","objective prior","empirical Bayes"],"title":"Regression modelling with I-priors: With applications to functional, multilevel and longitudinal data","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1590670800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"13804e4a317d12322b6406fcc412a9b4","permalink":"https://haziqj.ml/talk/investigating-the-effect-of-load-carriage-on-soldiers-performances-using-structural-equation-models/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/investigating-the-effect-of-load-carriage-on-soldiers-performances-using-structural-equation-models/","section":"event","summary":"Soldiers are required to perform tasks that call upon a complex combination of their physical and cognitive capabilities. For example, soldiers are expected to communicate effectively with each other, operate specialised equipment, and maintain overall situational awareness--often while carrying a heavy load. From a planning and doctrine perspective, it is important for commanders to understand the relationship between load carriage and soldiers’ performance. Such information could help provide recommendations in advising future policies on training, operational safety, and future soldier systems requirements. To this end, the Royal Brunei Armed Forces (RBAF) conducted controlled experiments and collected numerous measurements intended to capture key soldier performance parameters. The structure of the data set provided several interesting challenges, namely 1) how do we define “performance”?; 2) how do we appropriately take into account the longitudinal nature of the data (repeated measurements)?; and 3) how do we handle non-ignorable dropouts? We propose a structural equation model to quantify a latent variable representing soldiers' abilities, while taking into consideration the non-random nature of the dropouts and time-varying effects. The main output of the study is to quantify the relationship between load carried versus performance. Additionally, modelling the dropouts allow us to also determine “expected time to exhaustion” for a given load carried by a soldier.","tags":["Latent Variable Models","Structural Equation Models"],"title":"Investigating the effect of load carriage on soldiers’ performances using structural equation models","type":"event"},{"authors":null,"categories":null,"content":"","date":1584316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"1cda19dd8843ec96b438455bdcdcd736","permalink":"https://haziqj.ml/project/stat-tables/","publishdate":"2020-03-16T00:00:00Z","relpermalink":"/project/stat-tables/","section":"project","summary":"An open source PDF format of statistical tables for use in examinations, tests, assignments, and so on.","tags":["Statistical Tables","Misc"],"title":"Statistical Tables","type":"project"},{"authors":["Haziq Jamil","Ayesha Salleh","Le Thieng Chan"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"de3a34366f79cf5c9467f26a51be5443","permalink":"https://haziqj.ml/publication/jamil-2020-investigating/","publishdate":"2021-09-06T14:10:51.723746Z","relpermalink":"/publication/jamil-2020-investigating/","section":"publication","summary":"Soldiers are required to perform tasks that call upon a complex combination of their physical and cognitive capabilities. For example, soldiers are expected to communicate effectively with each other, operate specialised equipment, and maintain overall situational awareness---often while carrying a heavy load. From a planning and doctrine perspective, it is important for commanders to understand the relationship between load carriage and soldiers' performance. Such information could help provide recommendations in advising future policies on training, operational safety, and future soldier systems requirements. To this end, the Royal Brunei Armed Forces (RBAF) conducted controlled experiments and collected numerous measurements intended to capture key soldier performance parameters. The structure of the data set provided several interesting challenges, namely 1) How does one define ``performance''?; 2) How do we handle non-ignorable dropouts?; and 3) How do we appropriately take into account the longitudinal nature of the data (repeated measurements)? We propose a structural equation model to quantify a latent variable representing soldiers' abilities, while taking into consideration the non-random nature of the dropouts and time-varying effects. The main output of the study is to quantify the relationship between load carried versus performance. Additionally, modelling the dropouts allow us to also determine expected ``time to exhaustion'' for any given weight carried.","tags":[],"title":"Investigating the effect of load carriage on soldiers' performances using Bayesian structural equation models","type":"publication"},{"authors":["Haziq Jamil","Wicher Bergsma"],"categories":[],"content":"","date":1575072e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"393e88842313b2fd93b654ce2cb3db18","permalink":"https://haziqj.ml/publication/jamil-iprior-2019/","publishdate":"2021-09-06T14:10:50.772372Z","relpermalink":"/publication/jamil-iprior-2019/","section":"publication","summary":"This is an overview of the R package iprior, which implements a unified methodology for fitting parametric and nonparametric regression models, including additive models, multilevel models, and models with one or more functional covariates. Based on the principle of maximum entropy, an I-prior is an objective Gaussian process prior for the regression function with covariance kernel equal to its Fisher information. The regression function is estimated by its posterior mean under the I-prior, and hyperparameters are estimated via maximum marginal likelihood. Estimation of I-prior models is simple and inference straightforward, while small and large sample predictive performances are comparative, and often better, to similar leading state-of-the-art models. We illustrate the use of the iprior package by analysing a simulated toy data set as well as three real-data examples, in particular, a multilevel data set, a longitudinal data set, and a dataset involving a functional covariate.","tags":["Gaussian process regression","objective prior","empirical Bayes","RKHS","EM algorithm","Nystrom method","I-prior"],"title":"iprior: An R Package for Regression Modelling using I-priors","type":"publication"},{"authors":["Haziq Jamil"],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Wowchemy\u0026#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/). Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. -- ","date":1573653600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"af988344b8d94a14a102df14b3a13841","permalink":"https://haziqj.ml/talk/bayesian-variable-selection-for-linear-models/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/bayesian-variable-selection-for-linear-models/","section":"event","summary":"In statistical modelling, there is often a genuine interest to learn the most reasonable, parsimonious, and interpretable model that fits the data. This is especially true when faced with the oddly perplexing phenomenon of having \"too much information\" (data saturation). Model selection is indeed a vastly covered topic. In this talk, I will focus on the Bayesian approach to model selection, emphasising the selection of variables in a linear regression model. The outcome of the talk is three-fold: 1) To introduce the statistical framework for Bayesian variable selection; 2) to understand how we can use model probabilities as a basis for model selection; and 3) to demonstrate its application using real-world data (mortality and air pollution data). The hope is that the audience will gain an understanding of the method to possibly spur on further research and applications in their respective work.\"\n","tags":null,"title":"Bayesian Variable Selection for Linear Models","type":"event"},{"authors":["Haziq Jamil"],"categories":[],"content":"Introductory Data Science using R Lecture 1: The Data Science Framework\n Admin  Content available at https://haziqj.ml/teaching 4 x 2hr lectures 10min break on the hour Ask questions as we go along   Structure  Lecture 1: The data science framework Lecture 2: Using R Lecture 3: Data science with R Lecture 4: Exploratory analysis of Kiva.org data      The scientific method is an empirical method of acquiring knowledge that has characterized the development of science since at least the 17th century. It involves careful observation, applying rigorous skepticism about what is observed, given that cognitive assumptions can distort how one interprets the observation. It involves formulating hypotheses, via induction, based on such observations; experimental and measurement-based testing of deductions drawn from the hypotheses; and refinement (or elimination) of the hypotheses based on the experimental findings. These are principles of the scientific method, as distinguished from a definitive series of steps applicable to all scientific enterprises   The scientific inquiry data + model —\u0026gt; understand\n Not new, arises in many fields  Natural sciences Econometrics Psychology Sociology etc.     From a data science perspective, we are interested in the numerical aspects. qualitative vs quantitative It really is not new. Examples?    Giuseppe Piazzi’s observations in the Monatliche Correspondenz, September 1801.\n 18th century Collected data on position of a celestial object. Data and model show that the object did not behave like it was supposed to. Announced it as a comet but really was a planet.     Design of experiments; randomised control trials. Sir Ronald Fisher (1890–1962).   Fisher credited with the methods to analyze these types of data sets ANOVA Note the deliberate intent of collecting data for this specific purpose c.f. surveys    Data is now available by happenstance, and not just collected by design.\n Big Data The more we measure, the more we don’t understand\n Breadth vs depth paradox; Big p Small n; The curse of dimensionality “Data first” paradigm Ethics; privacy   Data collected was manageable and intended. E.g. surveys Computing power Able to quantify greater degree the actions of individuals, but less able to characterize society Data comes after the question. Often do not have the luxury of tailoring what data is collected. Fundamental statistics issues surrounding data are thrown out the window: precision and accuracy. bias in data.    define: Data Science\nThe “concept to unify statistics, data analysis, machine learning and their related methods” in order to “understand and analyze actual phenomena” with data.\n Multi-displinary field Goal: extract knowledge and insights from structured and unstructured data   In essence, need a systematic way of dealing with data. Need to combine knowledge from various fields. While every field was working in silos, they specialised in their own thing. Data science unites the fields of stats/maths and computer science to make data actionable.     Examples of Data Science problems Real-world problems from the Alan Turing Institute\n Real-time jammer detection, identification and localization in 3G and 4G networks Automated matching of businesses to government contract opportunities Using real-world data to advance air traffic control Personalised lung cancer treatment modelling using electronic health records and genomics   ATI is the national institute for data science and artificial intelligence. interesting to ponder, why was it named after Alan Turing, the comuting pioneer?    Examples of Data Science problems Real-world problems from the Alan Turing Institute\n Identify potential drivers of engaging in extremism News feed analysis to help understand global instability Improved strength training using smart gym equipment data    Scope: Exploratory     Focus on transform and visualise Modelling requires a specific skill set (Stats or ML) GOAL: Generate many promising leads that you can later explore in more depth   Machine Learning vs Statistics Statistics aims to turn humans into robots.\n Concept of “statistical proof” Often interest is inference  Machine learning aims to turn robots into humans.\n Make sense of patterns from big data Often interest is prediction   Statistics aims to remove the bias of humans when perceiving patterns in data sets. Learn not to be conned; when someone tells you it is such, need proof. Stats: How big is big, and is it enough? Measuring effects. Important question: causality? On the other hand ML or AI aims to equip computers with human skills: image understanding, speech recognition, natural language processing, etc. Kind of “reverse engineering” of world processes based on data that is observed. Generate large labelled data sets from humans. Train models. Interesting note: programming language also speaks as to what your background is. R for stats, Python for ML.    Data Quality and Readiness There’s a sea of data, but most of it …","date":1562630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"89ac91e20810a6d449048de588e2b351","permalink":"https://haziqj.ml/slides/teach-ds-1/","publishdate":"2019-07-09T00:00:00Z","relpermalink":"/slides/teach-ds-1/","section":"slides","summary":"Learn about the data science framework, including importing, summarising, and visualising data using R.","tags":[],"title":"Introductory Data Science using R","type":"slides"},{"authors":["Haziq Jamil"],"categories":[],"content":"Introductory Data Science using R R Exercise: The birthday problem\n In a room of 23 people, what is the probability that at least two people share the same birthday?\n Let’s count First, some assumptions:\n There are only 365 days in a year Every day is equally likely to be a birthday Everyone’s birthday is independent of each other  Strategy: It’s easier to figure out the probability of the complementary event. $$P(A) = 1 - P(A^c)$$   What’s the complement?  Let $A$ = At least two people share the same birthday Then $A^c$ = Nobody shares any birthday (all birthdays are different) Label the individuals from $1,\\dots,23$ How many possible birthdays can person 1 have? 365 out of 365 How many possible birthdays can person 2 have? 364 out of 365 …   What’s the complement?  Since all events are independent, $$P(A^c) = \\frac{365}{365} \\times \\frac{364}{365} \\times \\cdots \\times \\frac{365-23+1}{365}$$ $$= \\frac{365!}{(365-23)!365^{23}}$$ Thus, $$P(A) = 1 - \\frac{365!}{(365-23)!365^{23}}$$   Logarithms Factorials are often too large to compute and can cause memory overflow. Adopt the alternative formula\n$$P(A) = 1 - \\exp \\big\\{ \\log(365!) - \\log((365-23)!) $$ $$- 23 \\log 365 \\big\\}$$\n Write this in R Functions that you need:\n factorial() to compute factorials lfactorial() to compute log factorials exp() to compute exponentials   New question In a room of $x$ people, what is the probability that at least two people share the same birthday?\n Write this in R Write a function that takes a positive integer x and returns the probability that at least two people share the same birthday.\nBONUS: Plot it!\n","date":1562544e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"a1180d9965201e1f19581c591b971ef0","permalink":"https://haziqj.ml/slides/teach-ds-2/","publishdate":"2019-07-08T00:00:00Z","relpermalink":"/slides/teach-ds-2/","section":"slides","summary":"Part 2--Learn about the data science framework, including importing, summarising, and visualising data using R.","tags":[],"title":"Getting started with R","type":"slides"},{"authors":null,"categories":null,"content":"Truncated normal distributions often appear in the estimation of various important statistical models, for example, binary and multinomial probit models, tobit models, and constrained linear regresion. Often times, a substantial part of the estimation algorithm involves the computation of moments or probabilities of the truncated normal distribution. It is therefore important that the computational backend for producing these values of interest is made as efficient as possible.\nAmong other things, it would be interesting to look at the following:\n Efficient ways to obtain moments $\\text{E}[g(X)]$ where $X$ is distributed according to a truncated normal distribution. Efficient ways to obtain probabilities involving truncated normal distributions. Univariate and multivariate truncated normal distributions.  The main goal for this project is to create an R package which can be used by other developers and researchers for their specific usage.\nWork involved: literature review and survey of current methods, identifying bottlenecks in algorithms, propose methodology to overcome such bottlenecks, software design.\n","date":1552089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"d674c834b27da4107efdc00bd55b4060","permalink":"https://haziqj.ml/future-project/truncated-normal/","publishdate":"2019-03-09T00:00:00Z","relpermalink":"/future-project/truncated-normal/","section":"future-project","summary":"To explore efficient computational methods for evaluating truncated normal distributions.","tags":["Truncated Normal","R Package"],"title":"Efficient methods for truncated normal distributions","type":"future-project"},{"authors":null,"categories":null,"content":"Often, key constructs of interest remain elusive in a quantitative study because they are impossible to measure directly. Examples from social science studies include individuals’ intelligence quotient (IQ), or political tendencies (left or right). However, under a reflective measurement theory, we can propose that these constructs influence the outcome of several tests which can be measured directly (e.g., IQ can be measured by appropriate IQ tests, and political tendencies by appropriate survey questions).\nTaking this cue from the social sciences, it would be interesting to see this type of methodology being applied to sports and fitness. Spefically, this study comes from a performance optimisation standpoint. Under what conditions do athletes perform best? Athletes’ performance can be considered to be latent in nature, but several test items can be constructed to measure the latent variable indirectly.\nIt would also be interesting to construct a non-parametric relationship between several explanatory variables and the latent variable of interest in the structural part of the model. Doing so would allow for better flexibility and predictive abilities. One idea would be to include a Gaussian process regression (GPR) in the structural equation model.\nThis project can be applied in nature, but there is also substantive scope to look into methodology. For instance, a writeup of the estimation of such models when there is a GPR would certainly be noteworthy.\n","date":1552089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"d4bd4b3a24c8d232ac7e34e98b43199d","permalink":"https://haziqj.ml/future-project/latent-physical/","publishdate":"2019-03-09T00:00:00Z","relpermalink":"/future-project/latent-physical/","section":"future-project","summary":"To devise a suitable statistical model to produce scores for individuals' abilities relevant in the field of fitness and sports.","tags":["Latent Variable Models","Structural Equation Models"],"title":"Scoring individual abilities using multilevel latent variable models","type":"future-project"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1548406800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"76a993897186adf8d59d5e023ff88ed0","permalink":"https://haziqj.ml/talk/misconceptions-in-demography/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/misconceptions-in-demography/","section":"event","summary":"Inspired by the Gapminder project, let's talk about common misconceptions about demography.","tags":["Demography"],"title":"Misconceptions in Demography","type":"event"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1543933800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"d0bd5ea4ad97ae9b9fb40438b317771a","permalink":"https://haziqj.ml/talk/a-brief-guide-to-variational-inference/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/a-brief-guide-to-variational-inference/","section":"event","summary":"The fitting of complex statistical models that consists of latent or nuisance variables, in addition to various parameters to be estimated, likely involves overcoming an intractable integral. For instance, calculating the likelihood of such models require marginalising over the latent variables, and this may prove to be difficult computationally, either due to dimensionality or model design. Variational inference, or variational Bayes as it is also known, offers an efficient alternative to Markov chain Monte Carlo methods, the Laplace approximation, and quadrature methods. Rooted in Bayesian inference and popularised in machine learning, the main idea is to overcome the difficulties faced by working with “easy” density functions in lieu of the true posterior distribution. The approximating density function is chosen so as to minimise the (reverse) Kullback-Leilber divergence between them. The topics that will be discussed are mean-field distributions, the coordinate ascent algorithm, and approximation properties, with an example following. The hope is that the audience will gain a basic understanding of the method to possibly spur on further research and applications in their respective work.","tags":["Variational Inference"],"title":"A Brief Guide to Variational Inference","type":"event"},{"authors":["Haziq Jamil"],"categories":[],"content":"","date":1538352e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"aede9fe06a89bda5513ec2362c3be962","permalink":"https://haziqj.ml/publication/jamil-2018-phdthesis/","publishdate":"2021-09-06T14:10:51.446134Z","relpermalink":"/publication/jamil-2018-phdthesis/","section":"publication","summary":"Regression analysis is undoubtedly an important tool to understand the relationship between one or more explanatory and independent variables of interest. In this thesis, we explore a novel methodology for fitting a wide range of parametric and nonparametric regression models, called the I-prior methodology [(Bergsma, 2019)](https://doi.org/10.1016/j.ecosta.2019.10.002).\n\nWe assume that the regression function belongs to a reproducing kernel Hilbert or Kreĭn space of functions, and by doing so, allows us to utilise the convenient topologies of these vector spaces. This is important for the derivation of the Fisher information of the regression function, which might be infinite dimensional. Based on the principle of maximum entropy, an I-prior is an objective Gaussian process prior for the regression function with covariance function proportional to its Fisher information.\n\nOur work focusses on the statistical methodology and computational aspects of fitting I-priors models. We examine a likelihood-based approach (direct optimisation and EM algorithm) for fitting I-prior models with normally distributed errors. The culmination of this work is the `R` package [`iprior`](https://cran.r-project.org/package=iprior) which has been made publicly available on CRAN. The normal I-prior methodology is subsequently extended to fit categorical response models, achieved by ''squashing'' the regression functions through a probit sigmoid function. Estimation of I-probit models, as we call it, proves challenging due to the intractable integral involved in computing the likelihood. We overcome this difficulty by way of variational approximations. Finally, we turn to a fully Bayesian approach of variable selection using I-priors for linear models to tackle multicollinearity.\n\nWe illustrate the use of I-priors in various simulated and real-data examples. Our study advocates the I-prior methodology as being a simple, intuitive, and comparable alternative to similar leading state-of-the-art models.\n","tags":[],"title":"Regression modelling using priors depending on Fisher information covariance kernels (I-priors)","type":"publication"},{"authors":null,"categories":null,"content":"","date":153576e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"098d2bd5e0f399d42eef95c1c4c918b2","permalink":"https://haziqj.ml/project/r-iprobit/","publishdate":"2018-09-01T00:00:00Z","relpermalink":"/project/r-iprobit/","section":"project","summary":"Binary and multinomial probit regression using I-priors in `R`.","tags":["R Package","Probit Models"],"title":"R/iprobit","type":"project"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1522153800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"d0b440a5660c53de285635aed83f24ad","permalink":"https://haziqj.ml/talk/binary-and-multinomial-regression-using-fisher-information-covariance-kernels-i-priors/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/binary-and-multinomial-regression-using-fisher-information-covariance-kernels-i-priors/","section":"event","summary":"In a regression setting, we define an I-prior as a Gaussian process prior on the regression function with covariance kernel equal to its Fisher information. We present some methodology and computational work on estimating regression functions by working in the appropriate reproducing kernel Hilbert space of functions and assuming an I-prior on the function of interest. In a regression model with normally distributed errors, estimation is simple—maximum likelihood and the EM algorithm is employed. In the classification models (categorical response models), estimation is performed using variational inference. I-prior models perform comparatively well, and often better, to similar leading state-of-the-art models for use in prediction and inference. Applications are plentiful, including smoothing models, modelling multilevel data, longitudinal data, functional covariates, multi-class classification, and even spatiotemporal modelling.","tags":["I-prior","Spatial Models","Probit Models"],"title":"Binary and Multinomial Regression using Fisher Information Covariance Kernels (I-priors)","type":"event"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1517488200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"5cbd844c7ec464af0a443cda35bae168","permalink":"https://haziqj.ml/talk/a-beginners-guide-to-variational-inference/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/a-beginners-guide-to-variational-inference/","section":"event","summary":"Estimation of complex models that consists of latent variables and various parameters, in addition to the data that is observed, might involve overcoming an intractable integral. For instance, calculating the likelihood of such models require marginalising over the latent variables, and this may prove to be difficult computationally—either due to model design or dimensionality. Variational inference, or variational Bayes as it is also known, offers an efficient alternative to Markov chain Monte Carlo methods, the Laplace approximation, and quadrature methods. Rooted in Bayesian inference and popularised in machine learning, the main idea is to overcome the difficulties faced by working with “easy” density functions in lieu of the true posterior distribution. The approximating density function is chosen so as to minimise the (reverse) Kullback-Leilber divergence between them. The topics that will be discussed are mean-field distributions, the coordinate ascent algorithm, and its properties, with examples following. The hope is that the audience will gain a basic understanding of the method to possibly spur on further research and applications in their respective work.","tags":["Variational Inference"],"title":"A Beginner's Guide to Variational Inference","type":"event"},{"authors":["Wicher Bergsma","Haziq Jamil"],"categories":null,"content":"","date":1500384600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"99c8b6723dc638fbaf8ac2e5fb948bdd","permalink":"https://haziqj.ml/talk/regression-modelling-with-i-priors/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/regression-modelling-with-i-priors/","section":"event","summary":"This is an overview of a unified methodology for fitting parametric and nonparametric regression models, including additive models, multilevel models, and models with one or more functional covariates. We also discuss an associated R-package called iprior. An I-prior is an objective prior for the regression function, and is based on its Fisher information. The regression function is estimated by its posterior mean under the I-prior, and scale parameters are estimated via maximum marginal likelihood using an Expectation-Maximization (EM) algorithm. Regression modelling using I-priors has several attractive features: it requires no assumptions other than those pertaining to the model of interest; estimation and inference is relatively straightforward; and small and large sample performance can be better than Tikhonov regularization. We illustrate the use of the iprior package by analysing three well- known data sets, in particular, a multilevel data set, a longitudinal data set, and a dataset involving a functional covariate.","tags":["I-prior"],"title":"Regression Modelling with I-Priors","type":"event"},{"authors":["Haziq Jamil"],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways: - **Create** slides using Wowchemy\u0026#39;s [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/). Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page. -- ","date":1494244800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"7d05004a815d7cff781c0bb94cd2eb74","permalink":"https://haziqj.ml/talk/binary-probit-regression-with-i-priors/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/binary-probit-regression-with-i-priors/","section":"event","summary":"An extension of the I-prior methodology to binary response data is explored. Starting from a latent variable approach, it is assumed that there exists continuous, auxiliary random variables which decide the outcome of the binary responses. Fitting a classical linear regression model on these latent variables while assuming normality of the error terms leads to the well-known generalised linear model with a probit link. A more general regression approach is considered instead, in which an I-prior on the regression function, which lies in some reproducing kernel Hilbert space, is assumed. An I-prior distribution is Gaussian with mean chosen a priori, and covariance equal to the Fisher information for the regression function. By working with I-priors, the benefits of the methodology are brought over to the binary case - one of which is that it provides a unified model-fitting framework that includes additive models, multilevel models and models with one or more functional covariates. The challenge is in the estimation, and a variational approximation is employed to overcome the intractable likelihood. Several real-world examples are presented from analyses conducted in R.","tags":["I-prior","Probit models"],"title":"Binary probit regression with I-priors","type":"event"},{"authors":null,"categories":null,"content":"","date":1486598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"fd5fe7fd61e8a3c9a98593f9e4a8dc98","permalink":"https://haziqj.ml/project/mmn/","publishdate":"2017-02-09T00:00:00Z","relpermalink":"/project/mmn/","section":"project","summary":"A quantitative text analysis of Brunei's legislative council meeting hansards.","tags":["Quantitative Text Analysis","Misc"],"title":"MMN Brunei quantitative text analysis","type":"project"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1478176200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"ecad8bfca13df81f9daea3fb39a116db","permalink":"https://haziqj.ml/talk/i-priors-in-bayesian-variable-selection-from-reproducing-kernel-hilbert-spaces-to-hamiltonian-monte-carlo/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/i-priors-in-bayesian-variable-selection-from-reproducing-kernel-hilbert-spaces-to-hamiltonian-monte-carlo/","section":"event","summary":"I-priors are a class of objective priors for regression functions which makes use of its Fisher information in a function space framework. Currently, I am exploring the use of I-priors in Bayesian variable selection. My talk is a collection of ideas and methods that I picked up along the way in researching my work, in the hopes that it might be of interest and some use in the areas you are working on: 1) Estimation of I-prior models using likelihood methods; 2) The R/iprior package for fitting I-prior models; 3) Shrinkage properties of I-priors and how they link to L2 penalties with individual shrinkage parameters (and equivalently, individual variance hyper-parameters in a Bayesian setting); 4) Estimation of I-prior models in a fully-Bayes setting, with particular interest in the scale parameters; 5) Using Hamiltonian Monte Carlo to obtain better quality MCMC chains for the Bayesian I-prior model. I will also share some information on useful tools and software for reproducible research that I came across during my work, including Shiny apps, GitHub, RStudio (for package development), knitr, and Stan.","tags":["Hamiltonian Monte Carlo"],"title":"I-priors in Bayesian Variable Selection: From Reproducing Kernel Hilbert Spaces to Hamiltonian Monte Carlo","type":"event"},{"authors":null,"categories":null,"content":"I created two shiny apps to explain Hamiltonian Monte Carlo:\n https://haziqj.shinyapps.io/hmc1/ https://haziqj.shinyapps.io/hmc2/  ","date":1478131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"2e5915e2e78f01b515b4f3a17a935081","permalink":"https://haziqj.ml/project/hmc-shiny/","publishdate":"2016-11-03T00:00:00Z","relpermalink":"/project/hmc-shiny/","section":"project","summary":"Shiny apps for explaining Hamiltonian Monte Carlo.","tags":["Hamiltonian Monte Carlo","Misc"],"title":"Hamiltonian Monte Carlo explainer","type":"project"},{"authors":null,"categories":null,"content":"","date":1472342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"b8ee8da5d3f33ba85e78127cab1e2919","permalink":"https://haziqj.ml/project/r-ipriorbvs/","publishdate":"2016-08-28T00:00:00Z","relpermalink":"/project/r-ipriorbvs/","section":"project","summary":"Bayesian Variable Selection for Linear Models using I-priors in `R`.","tags":["R Package","I-prior","JAGS"],"title":"R/ipriorBVS","type":"project"},{"authors":null,"categories":null,"content":"","date":1471564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"b2156151337be53d98c41dfb46d06421","permalink":"https://haziqj.ml/project/r-iprior/","publishdate":"2016-08-19T00:00:00Z","relpermalink":"/project/r-iprior/","section":"project","summary":"An `R` package for I-prior regression.","tags":["I-prior","R Package"],"title":"R/iprior","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"0ceb55b6bb1e4423e3ee202ab0b10ece","permalink":"https://haziqj.ml/project/my-phd/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/my-phd/","section":"project","summary":"Regression modelling using priors with Fisher information covariance kernels (I-priors).","tags":["I-prior"],"title":"My PhD Project","type":"project"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1447849800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"d01f338f95937b65766443019a42b618","permalink":"https://haziqj.ml/talk/two-stage-bayesian-variable-selection-for-linear-models-using-i-priors/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/two-stage-bayesian-variable-selection-for-linear-models-using-i-priors/","section":"event","summary":"In a previous work, I showed that the use of I-priors in various linear models can be considered as a solution to the over-fitting problem. In that work, estimation was still done using maximum likelihood, so in a sense it was a kind of frequentist-Bayes approach. Switching over to a fully Bayesian framework, we now look at the problem of variable selection, specifically in an ordinary linear regression setting. The appeal of Bayesian methods are that it reduces the selection problem to one of estimation, rather than a true search of the variable space for the model that optimises a certain criterion. I will talk about several Bayesian variable selection methods out there in the literature, and how we can make use of I-priors to improve on results in the presence of multicollinearity.","tags":["I-prior","Bayesian Variable Selection"],"title":"Two-stage Bayesian variable selection for linear models using I-priors","type":"event"},{"authors":["Haziq Jamil"],"categories":null,"content":"","date":1432036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"f33f9c2ea2696966d8286ac31a1520b2","permalink":"https://haziqj.ml/talk/regression-modelling-using-i-priors/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/regression-modelling-using-i-priors/","section":"event","summary":"The I-prior methodology is a new modelling technique which aims to improve on maximum likelihood estimation of linear models when the dimensionality is large relative to the sample size. By putting a prior which is informed by the dataset (as opposed to a subjective prior), advantages such as model parsimony, lesser model assumptions, simpler estimation, and simpler hypothesis testing can be had. By way of introducing the I-prior methodology, we will give examples of linear models estimated using I-priors. This includes multiple regression models, smoothing models, random effects models, and longitudinal models. Research into this area involve extending the I-prior methodology to generalised linear models (e.g. logistic regression), Structural Equation Models (SEM), and models with structured error covariances.","tags":["I-prior"],"title":"Regression Modelling using I-Priors","type":"event"},{"authors":["Haziq Jamil"],"categories":[],"content":"","date":1277942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"3b6ef57b619aca3b03214eec7d3940a2","permalink":"https://haziqj.ml/publication/mastersthesis/","publishdate":"2021-09-06T14:10:51.870597Z","relpermalink":"/publication/mastersthesis/","section":"publication","summary":"This dissertation focusses mainly on the Bradley-Terry model and its extensions to in- vestigate three aspects of English Premier League football. Firstly, a comparison of the estimated model rankings with the actual league table will be discussed and how well the model serves as a predictor of the final standings at the end of the season after sev- eral games have been played. Secondly, a home advantage analysis of the teams will be conducted. Thirdly, an estimation of player rankings based on team performances will be attempted. All analyses were conducted in R using the glm() framework, with the exception of the third model, which was specifically coded and solved using an optimi- sation function in R. While the first two analyses generally showed a good fit and clear results, the third one was not as straightforward. The failure to find stationary points in the optimisation problem suggests more work needs to be done to refine the model.","tags":["Bradley-Terry models","football"],"title":"Analysis of paired comparison data using Bradley-Terry models with applications to football data","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://haziqj.ml/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/","section":"","summary":"","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://haziqj.ml/post/getting-started/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://haziqj.ml/slides/example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"","tags":null,"title":"","type":"slides"},{"authors":null,"categories":null,"content":"If the scheduling tool does not load, follow this link to my Calendly scheduling page.\n window.location.href = \u0026#34;http://example.com\u0026#34;  Page Redirection   If you are not redirected automatically, follow this link to example.   --   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717483334,"objectID":"b425770b72894590d76a0fbdbc3b13bd","permalink":"https://haziqj.ml/appointment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/appointment/","section":"","summary":"Book an appointment using the Calendly tool.","tags":null,"title":"Book an appointment","type":"page"}]
<!doctype html><html lang=en-gb><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=author content="Haziq Jamil"><meta name=description content="Statistician in perpetual training."><link rel=alternate hreflang=en-gb href=https://haziqj.ml/event/><meta name=theme-color content="#1565c0"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.95d53890c5839471cef2375b6c449b9f.css><link rel=alternate href=/event/index.xml type=application/rss+xml title="Haziq Jamil"><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu4b886e67ce091368601699b05489f639_45390_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu4b886e67ce091368601699b05489f639_45390_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://haziqj.ml/event/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@hajiq"><meta property="twitter:creator" content="@hajiq"><meta property="og:site_name" content="Haziq Jamil"><meta property="og:url" content="https://haziqj.ml/event/"><meta property="og:title" content="Recent & Upcoming Talks | Haziq Jamil"><meta property="og:description" content="Statistician in perpetual training."><meta property="og:image" content="https://haziqj.ml/media/icon_hu4b886e67ce091368601699b05489f639_45390_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://haziqj.ml/media/icon_hu4b886e67ce091368601699b05489f639_45390_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-gb"><title>Recent & Upcoming Talks | Haziq Jamil</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=ef9aefa335e6f17c33364f4f90b69bdf><script src=/js/wowchemy-init.min.e22a2a20712150175b9cd707be2d0584.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Haziq Jamil</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Haziq Jamil</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#01-about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#05-publications><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/#07-projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/#10-contact><span>Contact</span></a></li><li class=nav-item><a class=nav-link href=/cv><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Recent & Upcoming Talks</h1></div><div class=universal-wrapper><div class=row><div class=col-lg-12><div class=row id=talk_list><div class=col-lg-2><h3>2024</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>18 Oct 2024 3:00 PM &mdash; 4:00 PM</span>
<span class=middot-divider></span>
<span>Department of Statistics and Data Science, NUS, Singapore</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/weighted-pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/>Weighted pairwise likelihood goodness-of-fit tests for binary factor models</a></div><a href=/talk/weighted-pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/ class=summary-link><div class=article-style><p>Limited information goodness-of-fit (LIGOF) tests are increasingly recognized for their application in high-dimensional multivariate categorical data analysis. LIGOF tests address sparsity in contingency tables by leveraging summary statistics derived from univariate and bivariate residuals, effectively circumventing the reliability concerns associated with traditional goodness-of-fit tests. Previous studies on binary factor models have predominantly utilised maximum likelihood estimation, which itself can be computationally intensive when fitting large and complex models. This work examines the efficacy of LIGOF tests when composite likelihood estimation, specifically pairwise likelihood estimation, is used instead. Pairwise likelihood estimation offers a beneficial trade-off between computational efficiency and modelling accuracy in factor models, and hence the performance of LIGOF tests under this framework is of significant interest. The tests under consideration are based on quadratic forms of the residuals, including the classical Wald and Pearson tests. Modifications of these tests are also proposed, with the aim of further reducing computational complexity. Moreover, the study is expanded to include scenarios that involve complex sampling procedures with known weights, thereby broadening the applicability of our findings.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/plgof-nus target=_blank rel=noopener>Slides</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>15 Apr 2024 2:00 PM &mdash; 3:00 PM</span>
<span class=middot-divider></span>
<span>Data Analysis and Statistical Science, Ghent University, Belgium</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/weighted-pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/>Weighted pairwise likelihood goodness-of-fit tests for binary factor models</a></div><a href=/talk/weighted-pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/ class=summary-link><div class=article-style><p>Limited information goodness-of-fit (LIGOF) tests are increasingly recognized for their application in high-dimensional multivariate categorical data analysis. LIGOF tests address sparsity in contingency tables by leveraging summary statistics derived from univariate and bivariate residuals, effectively circumventing the reliability concerns associated with traditional goodness-of-fit tests. Previous studies on binary factor models have predominantly utilised maximum likelihood estimation, which itself can be computationally intensive when fitting large and complex models. This work examines the efficacy of LIGOF tests when composite likelihood estimation, specifically pairwise likelihood estimation, is used instead. Pairwise likelihood estimation offers a beneficial trade-off between computational efficiency and modelling accuracy in factor models, and hence the performance of LIGOF tests under this framework is of significant interest. The tests under consideration are based on quadratic forms of the residuals, including the classical Wald and Pearson tests. Modifications of these tests are also proposed, with the aim of further reducing computational complexity. Moreover, the study is expanded to include scenarios that involve complex sampling procedures with known weights, thereby broadening the applicability of our findings.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/plgof-gent/#/title-slide target=_blank rel=noopener>Slides</a></div></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2023</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>26 Oct 2023 1:00 PM &mdash; 2:00 PM</span>
<span class=middot-divider></span>
<span>Department of Statistics, LSE</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/spatio-temporal-modelling-of-property-prices-in-brunei-darussalam/>Spatio-temporal modelling of property prices in Brunei Darussalam</a></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/lse-rms-oct23 target=_blank rel=noopener>Slides</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>9 Aug 2023 2:00 PM &mdash; 3:00 PM</span>
<span class=middot-divider></span>
<span>FOS, UBD</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/>Pairwise likelihood goodness of fit tests for binary factor models</a></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/lavaan.bingof target=_blank rel=noopener>Code</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>27 Jul 2023 4:10 PM &mdash; 5:25 PM</span>
<span class=middot-divider></span>
<span>University of Maryland</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/>Pairwise likelihood goodness of fit tests for binary factor models</a></div><a href=/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/ class=summary-link><div class=article-style><p>Limited information goodness of fit (GOF) tests have gained recognition in the literature for high-dimensional multivariate categorical data analysis. Sparsity issues in the ensuing contingency tables impair the dependability of GOF tests but can be circumvented by considering summary statistics involving univariate and bivariate residuals. Prior work in this area for factor models have focused mainly on maximum likelihood estimation, which itself can be computationally intensive when fitting large and complex models. This present work examines limited information GOF tests when composite likelihood estimation, specifically pairwise likelihood estimation, is used instead. Pairwise likelihood estimation offers a beneficial trade-off between computational efficiency and modelling accuracy in factor models, and hence we wanted to examine the performance of limited information GOF tests under this framework. The tests under consideration are based on the Pearson chi-squared test statistic and the Wald test statistic. We propose modifications to each of these tests with the aim of further reducing computational complexity. We then extend our findings beyond independent sampling to situations where complex sampling procedures (with known weights) are employed.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/lavaan.bingof target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/pairwise-likelihood-goodness-of-fit-tests-for-binary-factor-models/July27-415p-Jamil.pdf target=_blank rel=noopener>Slides</a></div></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2022</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>16 Nov 2022 3:00 PM &mdash; 1 Feb 2018 4:00 PM</span>
<span class=middot-divider></span>
<span>Faculty of Science, NUS, Singapore</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/regression-modelling-using-i-priors/>Regression modelling using I-priors</a></div><a href=/talk/regression-modelling-using-i-priors/ class=summary-link><div class=article-style><p>Regression analysis is undoubtedly an important tool to understand the relationship between one or more explanatory and independent variables of interest. The problem of estimating a generic regression function in a model with normal errors is considered. For this purpose, a novel objective prior for the regression function is proposed, defined as the distribution maximizing entropy (subject to a suitable constraint) based on the Fisher information on the regression function. This prior is called the I-prior. The regression function is then estimated by its posterior mean under the I-prior, and accompanying hyperparameters are estimated via maximum marginal likelihood. Estimation of I-prior models is simple and inference straightforward, while predictive performances are comparative, and often better, to similar leading state-of-the-art models&ndash;as will be illustrated by several data examples. Further plans for research in this area are also presented, including variable selection for interaction effects and extending the I-prior methodology to non-Gaussian errors.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/regression-modelling-using-i-priors/nus-iprior.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/regression-modelling-using-i-priors/nus-iprior.pdf target=_blank rel=noopener>Slides</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span>Wicher Bergsma</span>, <span class=author-highlighted>Haziq Jamil</span></div><span>15 Jul 2022 9:15 AM &mdash; 10:15 AM</span>
<span class=middot-divider></span>
<span>University of Bologna, Italy</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/selecting-interaction-effects-in-additive-models-using-i-priors/>Selecting interaction effects in additive models using I-priors</a></div><a href=/talk/selecting-interaction-effects-in-additive-models-using-i-priors/ class=summary-link><div class=article-style><p>Additive models with interactions have been considered extensively in the literature, using estimation methods such as splines or Gaussian process regression. We present an alternative empirical-Bayes approach to selecting interaction effects using the I-prior approach introduced by Bergsma (2020). Using a parsimonious formulation of hierarchical interaction spaces, model selection is simplified. Furthermore, we present an efficient EM algo- rithm for estimating key hyperparameters. Simulations for linear regressions indicate competitive performance with methods such as the lasso and Bayesian variable selection using spike and slab priors or g-priors. However, our methodology is more gen- eral and can also be used with interacting nonlinear regression functions.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/my-phd/>Project</a></div></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2021</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>14 Nov 2021 3:00 PM &mdash; 4:15 PM</span>
<span class=middot-divider></span>
<span>Online event</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/mindef-scholars-sharing-session-life-after-mindef/>MINDEF Scholars Sharing Session: Life After MINDEF</a></div><a href=/talk/mindef-scholars-sharing-session-life-after-mindef/ class=summary-link><div class=article-style><p>Sharing experiences about life after leaving the defence sector.</p></div></a></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2020</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>19 Nov 2020 2:30 PM &mdash; 3:30 PM</span>
<span class=middot-divider></span>
<span>Lecture Room 2 (D2.8), Block D, Integrated Science Building, UBD</span></div><a href=/talk/a-latent-variable-model-for-maximal-performance-testing-with-dropouts-for-military-applications/><div class=img-hover-zoom><img src=/talk/a-latent-variable-model-for-maximal-performance-testing-with-dropouts-for-military-applications/featured_hub75f451566df5575ccbc32e11468bc4f_190164_808x455_fill_q75_h2_lanczos_smart1.webp height=455 width=808 class=article-banner alt="A latent variable model for maximal performance testing with dropouts for military applications" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/a-latent-variable-model-for-maximal-performance-testing-with-dropouts-for-military-applications/>A latent variable model for maximal performance testing with dropouts for military applications</a></div><a href=/talk/a-latent-variable-model-for-maximal-performance-testing-with-dropouts-for-military-applications/ class=summary-link><div class=article-style><p>Soldiers are expected to perform complex and demanding tasks during operations, often while carrying a heavy load. It is therefore important for commanders to understand the relationship between load carriage and soldiers’ performance, as such knowledge helps inform decision-making on training policies, operational doctrines, and future soldier systems requirements. In order to investigate this, repeated experiments were conducted to capture key soldier performance parameters under controlled conditions. The data collected was found to contain missing values due to dropouts as well as non-measurement. We propose a Bayesian structural equation model to quantify a latent variable representing soldiers’ abilities, while taking into consideration the non-random nature of the dropouts and time-varying effects. This talk describes the modelling exercise conducted, emphasising the statistical model-building process as well as the practical reporting of the outputs of the model.</p></div></a></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>28 May 2020 1:00 PM &mdash; 2:00 PM</span>
<span class=middot-divider></span>
<span>Online</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/investigating-the-effect-of-load-carriage-on-soldiers-performances-using-structural-equation-models/>Investigating the effect of load carriage on soldiers’ performances using structural equation models</a></div><a href=/talk/investigating-the-effect-of-load-carriage-on-soldiers-performances-using-structural-equation-models/ class=summary-link><div class=article-style><p>Soldiers are required to perform tasks that call upon a complex combination of their physical and cognitive capabilities. For example, soldiers are expected to communicate effectively with each other, operate specialised equipment, and maintain overall situational awareness&ndash;often while carrying a heavy load. From a planning and doctrine perspective, it is important for commanders to understand the relationship between load carriage and soldiers’ performance. Such information could help provide recommendations in advising future policies on training, operational safety, and future soldier systems requirements. To this end, the Royal Brunei Armed Forces (RBAF) conducted controlled experiments and collected numerous measurements intended to capture key soldier performance parameters. The structure of the data set provided several interesting challenges, namely 1) how do we define “performance”?; 2) how do we appropriately take into account the longitudinal nature of the data (repeated measurements)?; and 3) how do we handle non-ignorable dropouts? We propose a structural equation model to quantify a latent variable representing soldiers&rsquo; abilities, while taking into consideration the non-random nature of the dropouts and time-varying effects. The main output of the study is to quantify the relationship between load carried versus performance. Additionally, modelling the dropouts allow us to also determine “expected time to exhaustion” for a given load carried by a soldier.</p></div></a></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2019</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>13 Nov 2019 2:00 PM &mdash; 3:00 PM</span>
<span class=middot-divider></span>
<span>G.10, UBDSBE, Brunei</span></div><a href=/talk/bayesian-variable-selection-for-linear-models/><div class=img-hover-zoom><img src=/talk/bayesian-variable-selection-for-linear-models/featured_hud79b96bff337f44a339b8c7ef39210d3_836308_808x455_fill_q75_h2_lanczos_top_3.webp height=455 width=808 class=article-banner alt="Bayesian Variable Selection for Linear Models" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/bayesian-variable-selection-for-linear-models/>Bayesian Variable Selection for Linear Models</a></div><a href=/talk/bayesian-variable-selection-for-linear-models/ class=summary-link><div class=article-style><p>In statistical modelling, there is often a genuine interest to learn the most reasonable, parsimonious, and interpretable model that fits the data. This is especially true when faced with the oddly perplexing phenomenon of having &ldquo;too much information&rdquo; (data saturation). Model selection is indeed a vastly covered topic. In this talk, I will focus on the Bayesian approach to model selection, emphasising the selection of variables in a linear regression model. The outcome of the talk is three-fold: 1) To introduce the statistical framework for Bayesian variable selection; 2) to understand how we can use model probabilities as a basis for model selection; and 3) to demonstrate its application using real-world data (mortality and air pollution data). The hope is that the audience will gain an understanding of the method to possibly spur on further research and applications in their respective work."</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/bayesian-variable-selection-for-linear-models/sbe-bvs-slides.pdf target=_blank rel=noopener>Slides</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>25 Jan 2019 9:00 AM &mdash; 10:00 AM</span>
<span class=middot-divider></span>
<span>Ministry of Defence, Brunei</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/misconceptions-in-demography/>Misconceptions in Demography</a></div><a href=/talk/misconceptions-in-demography/ class=summary-link><div class=article-style><p>Inspired by the Gapminder project, let&rsquo;s talk about common misconceptions about demography.</p></div></a></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2018</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>4 Dec 2018 2:30 PM &mdash; 1 Feb 2018 3:00 PM</span>
<span class=middot-divider></span>
<span>Faculty of Science, UBD, Brunei</span></div><a href=/talk/a-brief-guide-to-variational-inference/><div class=img-hover-zoom><img src=/talk/a-brief-guide-to-variational-inference/featured_hu494d4507d40cfb42e9397982e26d3b5e_1249304_808x455_fill_q75_h2_lanczos_smart1.webp height=455 width=808 class=article-banner alt="A Brief Guide to Variational Inference" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/a-brief-guide-to-variational-inference/>A Brief Guide to Variational Inference</a></div><a href=/talk/a-brief-guide-to-variational-inference/ class=summary-link><div class=article-style><p>The fitting of complex statistical models that consists of latent or nuisance variables, in addition to various parameters to be estimated, likely involves overcoming an intractable integral. For instance, calculating the likelihood of such models require marginalising over the latent variables, and this may prove to be difficult computationally, either due to dimensionality or model design. Variational inference, or variational Bayes as it is also known, offers an efficient alternative to Markov chain Monte Carlo methods, the Laplace approximation, and quadrature methods. Rooted in Bayesian inference and popularised in machine learning, the main idea is to overcome the difficulties faced by working with “easy” density functions in lieu of the true posterior distribution. The approximating density function is chosen so as to minimise the (reverse) Kullback-Leilber divergence between them. The topics that will be discussed are mean-field distributions, the coordinate ascent algorithm, and approximation properties, with an example following. The hope is that the audience will gain a basic understanding of the method to possibly spur on further research and applications in their respective work.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/a-brief-guide-to-variational-inference/ubd-bgtvi-slides.pdf target=_blank rel=noopener>Slides</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>27 Mar 2018 12:30 PM &mdash; 2:00 PM</span>
<span class=middot-divider></span>
<span>LSE, London, United Kingdom</span></div><a href=/talk/binary-and-multinomial-regression-using-fisher-information-covariance-kernels-i-priors/><div class=img-hover-zoom><img src=/talk/binary-and-multinomial-regression-using-fisher-information-covariance-kernels-i-priors/featured_huee58c189a9656b0802fbe81bf88631ed_746944_808x455_fill_q75_h2_lanczos_smart1.webp height=455 width=808 class=article-banner alt="Binary and Multinomial Regression using Fisher Information Covariance Kernels (I-priors)" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/binary-and-multinomial-regression-using-fisher-information-covariance-kernels-i-priors/>Binary and Multinomial Regression using Fisher Information Covariance Kernels (I-priors)</a></div><a href=/talk/binary-and-multinomial-regression-using-fisher-information-covariance-kernels-i-priors/ class=summary-link><div class=article-style><p>In a regression setting, we define an I-prior as a Gaussian process prior on the regression function with covariance kernel equal to its Fisher information. We present some methodology and computational work on estimating regression functions by working in the appropriate reproducing kernel Hilbert space of functions and assuming an I-prior on the function of interest. In a regression model with normally distributed errors, estimation is simple—maximum likelihood and the EM algorithm is employed. In the classification models (categorical response models), estimation is performed using variational inference. I-prior models perform comparatively well, and often better, to similar leading state-of-the-art models for use in prediction and inference. Applications are plentiful, including smoothing models, modelling multilevel data, longitudinal data, functional covariates, multi-class classification, and even spatiotemporal modelling.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/binary-and-multinomial-regression-using-fisher-information-covariance-kernels-i-priors/iprobit-poster.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/haziqj/iprobit-poster target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/my-phd/>Project</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>1 Feb 2018 12:30 PM &mdash; 2:00 PM</span>
<span class=middot-divider></span>
<span>LSE, London, United Kingdom</span></div><a href=/talk/a-beginners-guide-to-variational-inference/><div class=img-hover-zoom><img src=/talk/a-beginners-guide-to-variational-inference/featured_hu827774f0ed1eccb3585251ed25983bbb_226381_808x455_fill_q75_h2_lanczos_center.webp height=455 width=808 class=article-banner alt="A Beginner's Guide to Variational Inference" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/a-beginners-guide-to-variational-inference/>A Beginner's Guide to Variational Inference</a></div><a href=/talk/a-beginners-guide-to-variational-inference/ class=summary-link><div class=article-style><p>Estimation of complex models that consists of latent variables and various parameters, in addition to the data that is observed, might involve overcoming an intractable integral. For instance, calculating the likelihood of such models require marginalising over the latent variables, and this may prove to be difficult computationally—either due to model design or dimensionality. Variational inference, or variational Bayes as it is also known, offers an efficient alternative to Markov chain Monte Carlo methods, the Laplace approximation, and quadrature methods. Rooted in Bayesian inference and popularised in machine learning, the main idea is to overcome the difficulties faced by working with “easy” density functions in lieu of the true posterior distribution. The approximating density function is chosen so as to minimise the (reverse) Kullback-Leilber divergence between them. The topics that will be discussed are mean-field distributions, the coordinate ascent algorithm, and its properties, with examples following. The hope is that the audience will gain a basic understanding of the method to possibly spur on further research and applications in their respective work.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/haziqj/soc-stat-meet-bgtvi target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/a-beginners-guide-to-variational-inference/soc-stat-meet-bgtvi-handout.pdf target=_blank rel=noopener>Slides</a></div></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2017</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span>Wicher Bergsma</span>, <span class=author-highlighted>Haziq Jamil</span></div><span>18 Jul 2017 1:30 PM &mdash; 3:00 PM</span>
<span class=middot-divider></span>
<span>University of Zürich, Switzerland</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/regression-modelling-with-i-priors/>Regression Modelling with I-Priors</a></div><a href=/talk/regression-modelling-with-i-priors/ class=summary-link><div class=article-style><p>This is an overview of a unified methodology for fitting parametric and nonparametric regression models, including additive models, multilevel models, and models with one or more functional covariates. We also discuss an associated R-package called iprior. An I-prior is an objective prior for the regression function, and is based on its Fisher information. The regression function is estimated by its posterior mean under the I-prior, and scale parameters are estimated via maximum marginal likelihood using an Expectation-Maximization (EM) algorithm. Regression modelling using I-priors has several attractive features: it requires no assumptions other than those pertaining to the model of interest; estimation and inference is relatively straightforward; and small and large sample performance can be better than Tikhonov regularization. We illustrate the use of the iprior package by analysing three well- known data sets, in particular, a multilevel data set, a longitudinal data set, and a dataset involving a functional covariate.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/my-phd/>Project</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>8 May 2017 12:00 PM &mdash; 12:35 PM</span>
<span class=middot-divider></span>
<span>LSE</span></div><a href=/talk/binary-probit-regression-with-i-priors/><div class=img-hover-zoom><img src=/talk/binary-probit-regression-with-i-priors/featured_huea072637c6b69f9820361e5b52362921_2521129_808x455_fill_q75_h2_lanczos_smart1.webp height=455 width=808 class=article-banner alt="Binary probit regression with I-priors" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/binary-probit-regression-with-i-priors/>Binary probit regression with I-priors</a></div><a href=/talk/binary-probit-regression-with-i-priors/ class=summary-link><div class=article-style><p>An extension of the I-prior methodology to binary response data is explored. Starting from a latent variable approach, it is assumed that there exists continuous, auxiliary random variables which decide the outcome of the binary responses. Fitting a classical linear regression model on these latent variables while assuming normality of the error terms leads to the well-known generalised linear model with a probit link. A more general regression approach is considered instead, in which an I-prior on the regression function, which lies in some reproducing kernel Hilbert space, is assumed. An I-prior distribution is Gaussian with mean chosen a priori, and covariance equal to the Fisher information for the regression function. By working with I-priors, the benefits of the methodology are brought over to the binary case - one of which is that it provides a unified model-fitting framework that includes additive models, multilevel models and models with one or more functional covariates. The challenge is in the estimation, and a variational approximation is employed to overcome the intractable likelihood. Several real-world examples are presented from analyses conducted in R.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/haziqjamil/phd-presentation-3 target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/my-phd/>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=http://phd3.haziqj.ml/phd-presentation-3-handout.pdf target=_blank rel=noopener>Slides</a></div></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2016</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>3 Nov 2016 12:30 PM &mdash; 2:00 PM</span>
<span class=middot-divider></span>
<span>LSE, London, United Kingdom</span></div><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/i-priors-in-bayesian-variable-selection-from-reproducing-kernel-hilbert-spaces-to-hamiltonian-monte-carlo/>I-priors in Bayesian Variable Selection: From Reproducing Kernel Hilbert Spaces to Hamiltonian Monte Carlo</a></div><a href=/talk/i-priors-in-bayesian-variable-selection-from-reproducing-kernel-hilbert-spaces-to-hamiltonian-monte-carlo/ class=summary-link><div class=article-style><p>I-priors are a class of objective priors for regression functions which makes use of its Fisher information in a function space framework. Currently, I am exploring the use of I-priors in Bayesian variable selection. My talk is a collection of ideas and methods that I picked up along the way in researching my work, in the hopes that it might be of interest and some use in the areas you are working on: 1) Estimation of I-prior models using likelihood methods; 2) The R/iprior package for fitting I-prior models; 3) Shrinkage properties of I-priors and how they link to L2 penalties with individual shrinkage parameters (and equivalently, individual variance hyper-parameters in a Bayesian setting); 4) Estimation of I-prior models in a fully-Bayes setting, with particular interest in the scale parameters; 5) Using Hamiltonian Monte Carlo to obtain better quality MCMC chains for the Bayesian I-prior model. I will also share some information on useful tools and software for reproducible research that I came across during my work, including Shiny apps, GitHub, RStudio (for package development), knitr, and Stan.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/haziqjamil/soc-stat-meet target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/my-phd/>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/i-priors-in-bayesian-variable-selection-from-reproducing-kernel-hilbert-spaces-to-hamiltonian-monte-carlo/soc-stat-meet-handout.pdf target=_blank rel=noopener>Slides</a></div></div></div></div><div class=row id=talk_list><div class=col-lg-2><h3>2015</h3></div><div class=col-lg-10><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>18 Nov 2015 12:30 PM &mdash; 2:00 PM</span>
<span class=middot-divider></span>
<span>LSE, London, United Kingdom</span></div><a href=/talk/two-stage-bayesian-variable-selection-for-linear-models-using-i-priors/><div class=img-hover-zoom><img src=/talk/two-stage-bayesian-variable-selection-for-linear-models-using-i-priors/featured_hu768a77dbaf39713e1bd8ca90d0181c4c_1483152_808x455_fill_q75_h2_lanczos_center.webp height=455 width=808 class=article-banner alt="Two-stage Bayesian variable selection for linear models using I-priors" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/two-stage-bayesian-variable-selection-for-linear-models-using-i-priors/>Two-stage Bayesian variable selection for linear models using I-priors</a></div><a href=/talk/two-stage-bayesian-variable-selection-for-linear-models-using-i-priors/ class=summary-link><div class=article-style><p>In a previous work, I showed that the use of I-priors in various linear models can be considered as a solution to the over-fitting problem. In that work, estimation was still done using maximum likelihood, so in a sense it was a kind of frequentist-Bayes approach. Switching over to a fully Bayesian framework, we now look at the problem of variable selection, specifically in an ordinary linear regression setting. The appeal of Bayesian methods are that it reduces the selection problem to one of estimation, rather than a true search of the variable space for the model that optimises a certain criterion. I will talk about several Bayesian variable selection methods out there in the literature, and how we can make use of I-priors to improve on results in the presence of multicollinearity.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/my-phd/>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/two-stage-bayesian-variable-selection-for-linear-models-using-i-priors/bvs-two-stage-slides.pdf target=_blank rel=noopener>Slides</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Haziq Jamil</span></div><span>19 May 2015 12:00 PM &mdash; 12:35 PM</span>
<span class=middot-divider></span>
<span>LSE, London, United Kingdom</span></div><a href=/talk/regression-modelling-using-i-priors/><div class=img-hover-zoom><img src=/talk/regression-modelling-using-i-priors/featured_hua4559c6eba59de78a2bec9749502c22f_114154_808x455_fill_q75_h2_lanczos_center.webp height=455 width=808 class=article-banner alt="Regression Modelling using I-Priors" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/talk/regression-modelling-using-i-priors/>Regression Modelling using I-Priors</a></div><a href=/talk/regression-modelling-using-i-priors/ class=summary-link><div class=article-style><p>The I-prior methodology is a new modelling technique which aims to improve on maximum likelihood estimation of linear models when the dimensionality is large relative to the sample size. By putting a prior which is informed by the dataset (as opposed to a subjective prior), advantages such as model parsimony, lesser model assumptions, simpler estimation, and simpler hypothesis testing can be had. By way of introducing the I-prior methodology, we will give examples of linear models estimated using I-priors. This includes multiple regression models, smoothing models, random effects models, and longitudinal models. Research into this area involve extending the I-prior methodology to generalised linear models (e.g. logistic regression), Structural Equation Models (SEM), and models with structured error covariances.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/my-phd/>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/talk/regression-modelling-using-i-priors/iprior-phd-presentation-slides.pdf target=_blank rel=noopener>Slides</a></div></div></div></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2024 Haziq Jamil. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.92d2024afaa4dce0cad42ba360879ce9.js></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.e8fd2d733eef6a8bbbe0539398fc0547.js type=module></script>
<script src=/en/js/wowchemy.min.de33c90527762392d440555c36739dd9.js></script>
<script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>